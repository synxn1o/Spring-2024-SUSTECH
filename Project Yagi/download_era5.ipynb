{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://codes.ecmwf.int/grib/param-db/ \\\n",
    "https://cds.climate.copernicus.eu/datasets/reanalysis-era5-pressure-levels?tab=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31.449, 81.805, 6.949000000000002, 145.805]\n"
     ]
    }
   ],
   "source": [
    "import cdsapi\n",
    "import numpy as np\n",
    "import netCDF4\n",
    "import os\n",
    "\n",
    "# Function to read area specifications from namelist.wps\n",
    "def read_area_from_namelist(namelist_path):\n",
    "    area = {}\n",
    "    with open(namelist_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if 'ref_lat' in line:\n",
    "                area['ref_lat'] = float(line.split('=')[1].strip())\n",
    "            elif 'ref_lon' in line:\n",
    "                area['ref_lon'] = float(line.split('=')[1].strip())\n",
    "            elif 'e_we' in line:\n",
    "                area['e_we'] = int(line.split('=')[1].strip())\n",
    "            elif 'e_sn' in line:\n",
    "                area['e_sn'] = int(line.split('=')[1].strip())\n",
    "    return area\n",
    "\n",
    "# Function to download ERA5 data\n",
    "def download_era5_data(start_date, end_date, time_step, pressure_levels, variables, area, output_dir):\n",
    "    c = cdsapi.Client()\n",
    "    dataset = 'reanalysis-era5-pressure-levels' if pressure_levels else 'reanalysis-era5-single-levels'\n",
    "    request = {\n",
    "        'product_type': 'reanalysis',\n",
    "        'format': 'netcdf',\n",
    "        'variable': variables,\n",
    "        'year': [str(year) for year in range(start_date[0], end_date[0] + 1)],\n",
    "        'month': [f'{month:02d}' for month in range(start_date[1], end_date[1] + 1)],\n",
    "        'day': [f'{day:02d}' for day in range(start_date[2], end_date[2] + 1)],\n",
    "        'time': [f'{hour:02d}:00' for hour in range(0, 24, time_step)],\n",
    "        'pressure_level': pressure_levels if pressure_levels else None,\n",
    "        'area': [area['ref_lat'] + area['e_sn'] * 0.25, area['ref_lon'] - area['e_we'] * 0.25,\n",
    "                 area['ref_lat'] - area['e_sn'] * 0.25, area['ref_lon'] + area['e_we'] * 0.25],\n",
    "        'grid': [0.25, 0.25]\n",
    "    }\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        target = os.path.join(output_dir, f'{start_date}{end_date}_all.nc')\n",
    "        c.retrieve(dataset, request, target)\n",
    "    else:\n",
    "        target = os.path.join(output_dir, f'{start_date}{end_date}_all.nc')\n",
    "        c.retrieve(dataset, request, target)\n",
    "\n",
    "# Download function\n",
    "def download_main(variables, pressure_levels,output_dir):\n",
    "    # Read area from namelist.wps\n",
    "    area = read_area_from_namelist('namelist_larger.wps')\n",
    "    print([area['ref_lat'] + area['e_sn'] * 0.25, area['ref_lon'] - area['e_we'] * 0.25, \\\n",
    "        area['ref_lat'] - area['e_sn'] * 0.25, area['ref_lon'] + area['e_we'] * 0.25])\n",
    "    # Define download parameters\n",
    "    start_date = (2024, 9, 4)  # Year, Month, Day\n",
    "    end_date = (2024, 9, 7)\n",
    "    time_step = 1  # Hours\n",
    "    # Download data\n",
    "    for date in range(start_date[2],end_date[2]+1):\n",
    "        day = (2024,9,date)\n",
    "        # download_era5_data(day, day, time_step, pressure_levels, variables, area, output_dir)\n",
    "\n",
    "pressure_levels = ['1000', '925', '850', '700', '600', '500', '400', '300', '200', '100']\n",
    "variables = [\n",
    "        \"geopotential\",\n",
    "        \"specific_humidity\",\n",
    "        \"temperature\",\n",
    "        \"u_component_of_wind\",\n",
    "        \"v_component_of_wind\",\n",
    "        \"vertical_velocity\",\n",
    "        \"vorticity\"\n",
    "    ]\n",
    "output_dir = 'era5_data'\n",
    "\n",
    "download_main(variables,pressure_levels,output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257, 99, 10, 24)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "variable_mapping = {\n",
    "    'u_component_of_wind': 'u',\n",
    "    'v_component_of_wind': 'v',\n",
    "    'temperature': 't',\n",
    "    'geopotential': 'z',\n",
    "    'dew_point_temperature': 'd',\n",
    "    'specific_humidity': 'q',\n",
    "    'relative_humidity': 'r',\n",
    "    'vorticity':'vo',\n",
    "    'vertical_velocity':'w'\n",
    "}\n",
    "start_date = (2024, 9, 3)  # Year, Month, Day\n",
    "end_date = (2024, 9, 7)\n",
    "# Function to convert NetCDF to NumPy .dat\n",
    "def convert_netcdf_to_numpy(variables, output_dir):\n",
    "    # Convert each NetCDF file to NumPy .dat\n",
    "    \n",
    "    for date in range(start_date[2],end_date[2]+1):\n",
    "        day = (2024,9,date)\n",
    "        netcdf_file = os.path.join(output_dir, f'{day}{day}_all.nc')\n",
    "        with netCDF4.Dataset(netcdf_file, 'r') as nc:\n",
    "            for var in variables:\n",
    "                output_file = os.path.join(output_dir, f'{day}{var}.dat')\n",
    "                data = np.array(nc.variables[variable_mapping[var]][:]).astype(np.float64)\n",
    "                data = np.transpose(data, axes=(3, 2, 1, 0))\n",
    "                data.flatten(order='F').tofile(output_file)\n",
    "    print(data.shape)\n",
    "\n",
    "        \n",
    "\n",
    "convert_netcdf_to_numpy(variables,output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added era5_data/(2024, 9, 3)geopotential.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 4)geopotential.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 5)geopotential.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 6)geopotential.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 7)geopotential.dat to concatenation list\n",
      "Created combined file: era5_data/combined_geopotential.dat\n",
      "Added era5_data/(2024, 9, 3)specific_humidity.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 4)specific_humidity.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 5)specific_humidity.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 6)specific_humidity.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 7)specific_humidity.dat to concatenation list\n",
      "Created combined file: era5_data/combined_specific_humidity.dat\n",
      "Added era5_data/(2024, 9, 3)temperature.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 4)temperature.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 5)temperature.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 6)temperature.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 7)temperature.dat to concatenation list\n",
      "Created combined file: era5_data/combined_temperature.dat\n",
      "Added era5_data/(2024, 9, 3)u_component_of_wind.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 4)u_component_of_wind.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 5)u_component_of_wind.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 6)u_component_of_wind.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 7)u_component_of_wind.dat to concatenation list\n",
      "Created combined file: era5_data/combined_u_component_of_wind.dat\n",
      "Added era5_data/(2024, 9, 3)v_component_of_wind.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 4)v_component_of_wind.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 5)v_component_of_wind.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 6)v_component_of_wind.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 7)v_component_of_wind.dat to concatenation list\n",
      "Created combined file: era5_data/combined_v_component_of_wind.dat\n",
      "Added era5_data/(2024, 9, 3)vertical_velocity.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 4)vertical_velocity.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 5)vertical_velocity.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 6)vertical_velocity.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 7)vertical_velocity.dat to concatenation list\n",
      "Created combined file: era5_data/combined_vertical_velocity.dat\n",
      "Added era5_data/(2024, 9, 3)vorticity.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 4)vorticity.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 5)vorticity.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 6)vorticity.dat to concatenation list\n",
      "Added era5_data/(2024, 9, 7)vorticity.dat to concatenation list\n",
      "Created combined file: era5_data/combined_vorticity.dat\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Function to concatenate .dat files for each variable\n",
    "def concatenate_dat_files():\n",
    "    for var in variables:\n",
    "        # Create a list to hold data for each date\n",
    "        all_data = []\n",
    "        \n",
    "        # Process each date\n",
    "        for date in range(start_date[2], end_date[2] + 1):\n",
    "            day = (2024, 9, date)\n",
    "            input_file = os.path.join(output_dir, f'{day}{var}.dat')\n",
    "            \n",
    "            try:\n",
    "                # Read data from file\n",
    "                data = np.fromfile(input_file, dtype=np.float64)\n",
    "                all_data.append(data)\n",
    "                print(f\"Added {input_file} to concatenation list\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Warning: File {input_file} not found, skipping\")\n",
    "        \n",
    "        if all_data:\n",
    "            # Concatenate all data for this variable\n",
    "            combined_data = np.concatenate(all_data)\n",
    "            \n",
    "            # Write to output file\n",
    "            output_file = os.path.join(output_dir, f'combined_{var}.dat')\n",
    "            combined_data.tofile(output_file)\n",
    "            print(all_data.shape)\n",
    "            print(f\"Created combined file: {output_file}\")\n",
    "        else:\n",
    "            print(f\"No data found for variable {var}\")\n",
    "\n",
    "# Execute the concatenation\n",
    "concatenate_dat_files()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netcdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
