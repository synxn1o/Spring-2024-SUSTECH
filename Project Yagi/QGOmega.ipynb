{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark: Describtion of Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Generated be GPT)\n",
    "| 文件名                  | 类型       | 描述                                                                                     |\n",
    "|-------------------------|------------|-----------------------------------------------------------------------------------------|\n",
    "| areamean.dat           | 原始输入文件 | 存放由 areamean.f 计算的区域平均后的 s 数据，用于描述区域内某物理量（如静态稳定性或湿度）的平均值。 |\n",
    "| DqDt.dat               | 最终结果     | 存放 DqDt.f 模块计算得到的最终诊断结果，包括 q、dqdt1、adv、wdqdp、DqDt 等量，用于分析量随时间的变化。 |\n",
    "| dTdt.dat               | 中间文件     | 存放温度时间变化率 dT/dt 的数据，作为 residue.f 等模块计算热能残差的输入。                     |\n",
    "| dsdpm.dat              | 中间文件     | 存放由 dsdpm.f 计算的压力层上 s 的垂直梯度（dsdp）数据，用于后续垂直修正计算。                   |\n",
    "| dsdx.dat               | 最终结果     | 存放 derivative_static.f 计算的 s 关于 x 方向的空间导数数据。                              |\n",
    "| dsdy.dat               | 最终结果     | 存放 derivative_static.f 计算的 s 关于 y 方向的空间导数数据。                              |\n",
    "| dsdz.dat               | 最终结果     | 存放 derivative_static.f 计算的 s 关于垂直方向（z 方向）的空间导数数据。                     |\n",
    "| dzdt_vort_g_adv.dat    | 最终结果     | 存放 relax_X.f 中计算的 geostrophic vorticity advection 的垂直微分结果。                  |\n",
    "| dzdt_T_g_adv.dat       | 最终结果     | 存放 relax_X.f 中计算的温度平流场（T_g_adv）垂直微分数据。                                |\n",
    "| dzdt_D.dat             | 中间文件     | 存放 relax_X.f 中计算的 D 模块垂直微分数据，后续由 trap.f 进行插值处理。                    |\n",
    "| F_D.dat                | 最终结果     | 存放 relax_X.f 计算得到的强迫函数 F 数据，与 diabatic heating 及其他因子相关。              |\n",
    "| omega.dat              | 原始输入文件 | 存放初始的涡度数据（相对涡度），作为 residue.f 等模块的输入。                              |\n",
    "| omega_D.dat            | 最终结果     | 存放 relax_omega.f 计算的与 D 相关的 omega 强迫项数据。                                   |\n",
    "| omega_T_g_adv.dat      | 最终结果     | 存放 relax_omega.f 计算的与温度平流相关的 omega 数据。                                    |\n",
    "| omega_vort_g_adv.dat   | 最终结果     | 存放 relax_omega.f 计算的与涡度平流相关的 omega 数据。                                    |\n",
    "| z.dat                  | 原始输入文件 | 存放高度场或位势高度数据，作为计算涡度、散度、地转平流等的基础场。                          |\n",
    "| X_analysis.dat         | 最终结果     | 存放 X_analysis.f 分析后修正的 X 域数据，反映经过调整后的诊断结果。                         |\n",
    "| u.dat                  | 原始输入文件 | 存放模型中或观测的 zonal wind（东向风）数据。                                             |\n",
    "| v.dat                  | 原始输入文件 | 存放模型中或观测的 meridional wind（北向风）数据。                                         |\n",
    "| shum.dat               | 原始输入文件 | 存放比湿或相关湿度数据（shum 通常代表 specific humidity）。                                |\n",
    "| T.dat                  | 原始输入文件 | 存放温度数据，作为温度平流和静态稳定性等计算的基础场。                                     |\n",
    "| T_adv.dat              | 最终结果     | 存放 T_adv.f 计算得到的温度平流场数据，反映温度随流场的输送情况。                          |\n",
    "| T_g_adv.dat            | 中间文件     | 存放 T_g_adv.f 计算的地转温度平流数据，通过地转平衡近似计算得到。                           |\n",
    "| s.dat                  | 中间文件     | 存放静态/热力学相关的 s 数据（可能与静稳定性或湿静力有关），作为多模块输入。                  |\n",
    "| zeta_g.dat             | 中间文件     | 存放 vort_g.f 计算的地转相对涡度数据，基于位势高度场 z 推导。                              |\n",
    "| dzetag_dt.dat          | 最终结果     | 存放 vort_tend.f 计算的地转相对涡度的时间变化率（涡度趋势）。                              |\n",
    "| zeta.dat               | 最终结果     | 存放 vort.f 计算的实际相对涡度数据，从风场 u、v 中推导。                                   |\n",
    "| eta.dat                | 最终结果     | 存放 vort.f 计算的实际绝对涡度数据（相对涡度加上行星涡度）。                               |\n",
    "| divg.dat               | 最终结果     | 存放 divg.f 计算的地转散度数据，基于位势高度场计算得到。                                   |\n",
    "| mdzdt_D.dat            | 最终结果     | 存放 trap.f 处理后经插值或平滑的 dzdt_D 数据。                                            |\n",
    "| eta_g.dat              | 中间文件     | 存放 vort_g.f 与 vort_g_adv.f 计算的地转绝对涡度数据。                                     |\n",
    "| div.dat                | 最终结果     | 存放 div.f 计算的实际散度数据，基于 u、v 风场的差分结果。                                  |\n",
    "\n",
    "\\ \\\n",
    "| Fortran 文件           | 功能描述                             | 主要计算/处理数据                                                                 |\n",
    "|-------------------------|--------------------------------------|----------------------------------------------------------------------------------|\n",
    "| relax_omega.f          | 利用松弛法求解或调整场中相关变量       | 计算并输出 s 的空间梯度（dsdx、dsdy、dsdz）等；可能用于调整涡度场。                 |\n",
    "| X_analysis.f           | 对 X 域进行分析和修正                 | 计算 X 分析结果，生成 X_analysis.dat。                                            |\n",
    "| DqDt.f                 | 诊断量 q 及其时间变化率 dq/dt 的计算   | 计算 q、dqdt1、adv、wdqdp、DqDt 等，输出最终结果 DqDt.dat。                        |\n",
    "| T_adv.f                | 计算温度平流场（T_adv）的诊断         | 利用风场与温度数据计算温度输送，输出 T_adv.dat。                                   |\n",
    "| dTdt.f                 | 计算温度的时间导数 dT/dt             | 生成温度变化率数据，供 residue.f 等模块使用。                                      |\n",
    "| derivative_static.f    | 计算静态场 s 的空间导数               | 计算 s 关于 x、y、z 的梯度，分别输出 dsdx.dat、dsdy.dat、dsdz.dat。                |\n",
    "| relax_X.f              | 对 X 域进行迭代松弛修正，并计算强迫函数 F | 利用 adv、res、dsdp 等数据迭代修正 X，输出 X 修正结果及 F_D.dat。                  |\n",
    "| areamean.f             | 计算区域$\\sigma$平均值                       | 读取 s (sigma)数据，计算指定区域内的平均值，输出 areamean.dat。                           |\n",
    "| T_g_adv.f              | 计算地转温度平流场                   | 结合 z 与 T 数据利用地转平衡近似计算，输出 T_g_adv.dat。                           |\n",
    "| dsdpm.f                | 计算压力层上 s 的垂直梯度（dsdp）     | 基于 areamean.dat 计算 dsdp，输出 dsdpm.dat。                                      |\n",
    "| vort_tend.f            | 计算地转相对涡度的时间趋势（dζg/dt）  | 对比连续时次 zeta_g 数据求差分，输出 dzetag_dt.dat。                               |\n",
    "| residue.f              | 计算热能方程残差，即 (dH/dt)/Cp 的诊断 | 综合 dTdt、温度平流、涡度等因素，输出 residue.dat。                                |\n",
    "| vort.f                 | 计算实际涡度（相对涡度与绝对涡度）     | 从 u、v 风场计算相对涡度 zeta，再加行星涡度得到 eta，输出 zeta.dat 与 eta.dat。     |\n",
    "| divg.f                 | 计算地转散度                         | 利用位势高度 z 及地转平衡公式计算，输出 divg.dat。                                 |\n",
    "| trap.f                 | 对 dzdt_D 数据进行插值或平滑处理       | 采用梯形法对 dzdt_D.dat 数据平滑，输出 mdzdt_D.dat。                               |\n",
    "| vort_g.f               | 计算地转相对涡度及地转绝对涡度         | 基于 z 数据计算地转相对涡度 zeta_g，并由其得到 eta_g，输出 zeta_g.dat 与 eta_g.dat。 |\n",
    "| div.f                  | 计算实际散度（非地转）                | 从 u、v 风场差分求散度，输出 div.dat。                                            |\n",
    "| static.f               | 计算静态稳定性相关量 s               | 利用 T、p、常数等计算 s（静态稳定性或湿静力参数），输出 s.dat。                    |\n",
    "| output_DqDt.f          | 驱动并输出 DqDt 诊断结果，用于检验与展示 | 读取 DqDt 相关数据，打印 q、dqdt1、adv、wdqdp、DqDt 等结果。                       |\n",
    "| vort_g_adv.f           | 计算地转涡度平流（vorticity advection）的诊断 | 结合 z 与 eta_g 数据计算涡度平流 adv，输出 vort_g_adv.dat。                        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark: Files Dependency Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Fortran source code directory\n",
    "directory = \"/mnt/e/proj_yagi/\"\n",
    "\n",
    "# List all Fortran files (.f)\n",
    "fortran_files = [f for f in os.listdir(directory) if f.endswith(\".f\")]\n",
    "\n",
    "# Global dictionary to record each .dat file's read and write info.\n",
    "# Format: { dat_filename: {\"read_by\": set(), \"write_by\": set()} }\n",
    "dat_info = {}\n",
    "\n",
    "# Also, record for each Fortran file, which .dat files are opened for read and write\n",
    "fortran_usage = {f: {\"read\": set(), \"write\": set()} for f in fortran_files}\n",
    "\n",
    "# Process each Fortran file\n",
    "for fortran_file in fortran_files:\n",
    "    filepath = os.path.join(directory, fortran_file)\n",
    "    try:\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            content = f.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {fortran_file}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Handle Fortran continuation lines: remove newlines after \"&\"\n",
    "    content = re.sub(r\"&\\s*\\n\\s*\", \"\", content)\n",
    "\n",
    "    # Find open statements, capturing the arguments between parentheses\n",
    "    open_pattern = re.compile(r\"open\\s*$(.*?)$\", re.IGNORECASE | re.DOTALL)\n",
    "    open_matches = open_pattern.findall(content)\n",
    "    # Map unit to .dat file for this file\n",
    "    local_unit_to_dat = {}\n",
    "    for match in open_matches:\n",
    "        unit_match = re.search(r\"unit\\s*=\\s*(\\d+)\", match, re.IGNORECASE)\n",
    "        file_match = re.search(r\"file\\s*=\\s*['\\\"]([^'\\\"]+\\.dat)['\\\"]\", match, re.IGNORECASE)\n",
    "        if unit_match and file_match:\n",
    "            unit = unit_match.group(1)\n",
    "            dat_file = file_match.group(1)\n",
    "            local_unit_to_dat[unit] = dat_file\n",
    "            if dat_file not in dat_info:\n",
    "                dat_info[dat_file] = {\"read_by\": set(), \"write_by\": set()}\n",
    "    \n",
    "    # Process read statements: find unit in read(...)\n",
    "    read_pattern = re.compile(r\"read\\s*$\\s*(\\d+)\\s*,\", re.IGNORECASE)\n",
    "    read_matches = read_pattern.findall(content)\n",
    "    for unit in read_matches:\n",
    "        if unit in local_unit_to_dat:\n",
    "            dat_file = local_unit_to_dat[unit]\n",
    "            dat_info[dat_file][\"read_by\"].add(fortran_file)\n",
    "            fortran_usage[fortran_file][\"read\"].add(dat_file)\n",
    "    \n",
    "    # Process write statements: find unit in write(...)\n",
    "    write_pattern = re.compile(r\"write\\s*$\\s*(\\d+)\\s*,\", re.IGNORECASE)\n",
    "    write_matches = write_pattern.findall(content)\n",
    "    for unit in write_matches:\n",
    "        if unit in local_unit_to_dat:\n",
    "            dat_file = local_unit_to_dat[unit]\n",
    "            dat_info[dat_file][\"write_by\"].add(fortran_file)\n",
    "            fortran_usage[fortran_file][\"write\"].add(dat_file)\n",
    "\n",
    "# Create table 1: For each .dat file: role (original, intermediate, final), read by, write by.\n",
    "dat_rows = []\n",
    "for dat_file, ops in dat_info.items():\n",
    "    read_by = ops[\"read_by\"]\n",
    "    write_by = ops[\"write_by\"]\n",
    "    if read_by and not write_by:\n",
    "        role = \"原始输入文件\"\n",
    "    elif write_by and not read_by:\n",
    "        role = \"最终结果\"\n",
    "    elif read_by and write_by:\n",
    "        role = \"中间文件\"\n",
    "    else:\n",
    "        role = \"未知类型\"\n",
    "    dat_rows.append({\n",
    "        \"dat_file\": dat_file,\n",
    "        \"role\": role,\n",
    "        \"read_by\": \", \".join(sorted(read_by)) if read_by else \"\",\n",
    "        \"write_by\": \", \".join(sorted(write_by)) if write_by else \"\"\n",
    "    })\n",
    "\n",
    "df_dat = pd.DataFrame(dat_rows)\n",
    "df_dat = df_dat.sort_values(by=[\"role\", \"dat_file\"]).reset_index(drop=True)\n",
    "\n",
    "# Create table 2: For each Fortran file: which .dat files read and which .dat files written.\n",
    "fortran_rows = []\n",
    "for f_file, usage in fortran_usage.items():\n",
    "    fortran_rows.append({\n",
    "        \"Fortran_file\": f_file,\n",
    "        \"read\": \", \".join(sorted(usage[\"read\"])) if usage[\"read\"] else \"\",\n",
    "        \"write\": \", \".join(sorted(usage[\"write\"])) if usage[\"write\"] else \"\"\n",
    "    })\n",
    "\n",
    "df_fortran = pd.DataFrame(fortran_rows)\n",
    "df_fortran = df_fortran.sort_values(by=[\"Fortran_file\"]).reset_index(drop=True)\n",
    "\n",
    "display(df_dat, df_fortran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设之前已经生成了 df_dat 与 df_fortran，如下示例：\n",
    "# df_dat 的列包括: \"dat文件\", \"类型\", \"read by\", \"write by\"\n",
    "# df_fortran 的列包括: \"Fortran文件\", \"打开(读取)的dat文件\", \"输出(写入)的dat文件\"\n",
    "# 这里直接使用之前的 DataFrame 对象\n",
    "\n",
    "# 构造便于查询的字典\n",
    "dat_dict = {}\n",
    "for idx, row in df_dat.iterrows():\n",
    "    dat_file = row[\"dat_file\"]\n",
    "    # 将 read_by 和 write_by 按逗号分隔转换为集合（去除空格）\n",
    "    read_by = set(x.strip() for x in row[\"read_by\"].split(\",\") if x.strip()) if row[\"read_by\"] else set()\n",
    "    write_by = set(x.strip() for x in row[\"write_by\"].split(\",\") if x.strip()) if row[\"write_by\"] else set()\n",
    "    dat_dict[dat_file] = {\"type\": row[\"role\"], \"read_by\": read_by, \"write_by\": write_by}\n",
    "\n",
    "fortran_dict = {}\n",
    "for idx, row in df_fortran.iterrows():\n",
    "    f_file = row[\"Fortran_file\"]\n",
    "    read_files = set(x.strip() for x in row[\"read\"].split(\",\") if x.strip()) if row[\"read\"] else set()\n",
    "    write_files = set(x.strip() for x in row[\"write\"].split(\",\") if x.strip()) if row[\"write\"] else set()\n",
    "    fortran_dict[f_file] = {\"read\": read_files, \"write\": write_files}\n",
    "\n",
    "# 定义递归函数，构造依赖树（树节点包含 name 和 children）\n",
    "def build_tree(dat_file, visited=None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    if dat_file in visited:\n",
    "        return {\"name\": dat_file + \" (循环依赖)\", \"children\": []}\n",
    "    visited.add(dat_file)\n",
    "    node = {\"name\": dat_file, \"children\": []}\n",
    "    # 如果该文件不是“原始输入文件”，则它应当是被某个Fortran文件写入\n",
    "    if dat_file in dat_dict and dat_dict[dat_file][\"write_by\"]:\n",
    "        # 对每个写入该dat文件的 Fortran 文件建立节点\n",
    "        for f in sorted(dat_dict[dat_file][\"write_by\"]):\n",
    "            f_node = {\"name\": f, \"children\": []}\n",
    "            # 查找该 Fortran 文件打开(读取)的 .dat 文件，作为它的依赖项\n",
    "            if f in fortran_dict and fortran_dict[f][\"read\"]:\n",
    "                for in_dat in sorted(fortran_dict[f][\"read\"]):\n",
    "                    child = build_tree(in_dat, visited.copy())\n",
    "                    f_node[\"children\"].append(child)\n",
    "            node[\"children\"].append(f_node)\n",
    "    return node\n",
    "\n",
    "# 定义一个函数，采用类似 Windows tree 的格式输出依赖树\n",
    "def print_tree(node, indent=\"\", last=True):\n",
    "    if indent == \"\":\n",
    "        # 根节点直接输出名称\n",
    "        print(node[\"name\"])\n",
    "    else:\n",
    "        connector = \"└── \" if last else \"├── \"\n",
    "        print(indent + connector + node[\"name\"])\n",
    "    child_count = len(node[\"children\"])\n",
    "    for i, child in enumerate(node[\"children\"]):\n",
    "        new_indent = indent + (\"    \" if last else \"│   \")\n",
    "        print_tree(child, new_indent, i == child_count - 1)\n",
    "\n",
    "# 输入期望的 .dat 文件（例如 \"omega_D.dat\"），构造并打印依赖树\n",
    "expected_dat = \"omega_D.dat\"  # 你可以修改为其它期望的文件\n",
    "tree = build_tree(expected_dat)\n",
    "print(\"Dependent Tree\")\n",
    "print_tree(tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabatically forced omega: omega_D.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Dependency Tree\n",
    "omega_D.dat\n",
    "    └── relax_omega_D.f\n",
    "        ├── areamean.dat\n",
    "        │   └── areamean.f\n",
    "        │       └── s.dat\n",
    "        │           └── static.f\n",
    "        │               └── T.dat\n",
    "        └── residue.dat\n",
    "            └── residue.f\n",
    "                ├── T_g_adv.dat\n",
    "                │   └── T_g_adv.f\n",
    "                │       ├── T.dat\n",
    "                │       └── z.dat\n",
    "                ├── dTdt.dat\n",
    "                │   └── dTdt.f\n",
    "                │       └── T.dat\n",
    "                ├── omega.dat\n",
    "                └── s.dat\n",
    "                    └── static.f\n",
    "                        └── T.dat\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess: T.dat -> sigma.dat, static.f -> static.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This script computes the static stability parameter 's' from a random temperature field, \\\n",
    "mimicking the Fortran program 'static.f'. It generates a random initial field for T instead\n",
    "of reading it from a file.\n",
    "\n",
    " - Input: \n",
    "    - Temprature Field T.dat with dimensions (73, 37, 10, 20). \n",
    "\n",
    "- Output: \n",
    "    - s.dat: computed stability parameter 's' or $\\sigma$, unformatted binary file containing the \n",
    "             with dimensions (73, 37, 9, 20) stored in Fortran (column-major) order. \n",
    " - Constants: \n",
    "    - c = 1004.0    (specific heat at constant padvsure, J/(kg·K)) \\\n",
    "    - r = 287.0     (gas constant for dry air, J/(kg·K)) \\ \n",
    "    - Pressure levels (in hPa): [1000, 925, 850, 700, 600, 500, 400, 300, 200, 100] \\\n",
    "    \n",
    "For each grid point (i,j) and time step n, the static stability parameter is computed \\\n",
    "for padvsure levels corresponding to Fortran indices k = 2 to 9 (Python indices 1 to 8) as: \n",
    "\n",
    "    s(i,j,k,n) = (r/p(k)) * [ r*T(i,j,k,n)/(p(k)*c) -\n",
    "                   (dp2*T(i,j,k-1,n) + (dp1-dp2)*T(i,j,k,n) - dp1*T(i,j,k+1,n))/(2*dp1*dp2) ]\n",
    "\n",
    "$$\n",
    "s(i,j,k,n) = \\frac{r}{p(k)} \\left( \\frac{r T(i,j,k,n)}{p(k) c} - \\frac{dp_2 T(i,j,k-1,n) + (dp_1 - dp_2) T(i,j,k,n) - dp_1 T(i,j,k+1,n)}{2 \\times dp_1 \\times dp_2} \\right)\n",
    "$$\n",
    "\n",
    "where: \\\n",
    "    dp1 = p(k-1) - p(k) \\\n",
    "    dp2 = p(k)   - p(k+1) \\\n",
    "Note: Fortran indices start at 1; in Python, they are mapped to 0-based indices. \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.2953307859621509)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sigma.py\n",
    "import numpy as np\n",
    "def compute_sigma(T: np.ndarray, p: np.ndarray = np.array([1000, 925, 850, 700, 600, 500, 400, 300, 200, 100])):\n",
    "    \"\"\"\n",
    "    Compute the stability parameter 'sigma' for T field.\n",
    "\n",
    "    Parameters:\n",
    "    - T (numpy.ndarray): Temperature field array with dimensions (n_i, n_j, n_k, n_n).\n",
    "    - p (numpy.ndarray): Pressure levels in hPa as a 1D array.\n",
    "\n",
    "    Returns:\n",
    "    - sigma (numpy.ndarray): Computed stability parameter array with dimensions (n_i, n_j, n_k, n_n), filled with zero-layer at k=0 and -1.\n",
    "    \"\"\"\n",
    "\n",
    "    # Constants\n",
    "    c = 1004.0  # Specific heat at constant pressure (J/(kg·K))\n",
    "    r = 287.0   # Gas constant for dry air (J/(kg·K))\n",
    "\n",
    "    # Dimensions\n",
    "    n_i, n_j, n_k, n_n = T.shape\n",
    "\n",
    "    # Allocate array for stability parameter 'sigma'\n",
    "    sigma = np.zeros((n_i, n_j, n_k, n_n), dtype=np.float64)\n",
    "\n",
    "    # Prepare pressure levels for broadcasting\n",
    "    p_b = p[1:n_k-1].reshape((1, 1, n_k-2, 1))  # k starts from the 2nd term (index=1)\n",
    "    dp1 = p[0:n_k-2] - p[1:n_k-1]  # dp1 = p(k-1) - p(k)\n",
    "    dp2 = p[1:n_k-1] - p[2:n_k]    # dp2 = p(k) - p(k+1)\n",
    "    dp1_b = dp1.reshape((1, 1, n_k-2, 1))\n",
    "    dp2_b = dp2.reshape((1, 1, n_k-2, 1))\n",
    "\n",
    "    # Extract slices for computation\n",
    "    var_k = T[:, :, 1:(n_k-1), :]  # k\n",
    "    var_km = T[:, :, 0:(n_k-2), :]  # k-1\n",
    "    var_kp = T[:, :, 2:n_k, :]      # k+1\n",
    "\n",
    "    # Compute the stability parameter for interior levels\n",
    "    sigma_interior = (r / p_b) * ((r * var_k) / (p_b * c) - \n",
    "                                  ((dp2_b * var_km + (dp1_b - dp2_b) * var_k - dp1_b * var_kp) / \n",
    "                                   (2 * dp1_b * dp2_b)))\n",
    "\n",
    "    # Assign the computed values to the sigma array\n",
    "    sigma[:, :, 1:n_k-1, :] = sigma_interior\n",
    "\n",
    "    # Save the computed stability parameter to a file\n",
    "    # sigma.flatten(order='F').tofile(output_file)\n",
    "\n",
    "    return sigma\n",
    "\n",
    "n_i, n_j, n_k, n_n = 73, 37, 10, 20\n",
    "p = np.array([1000, 925, 850, 700, 600, 500, 400, 300, 200, 100])\n",
    "\n",
    "T_dat = \"T.dat\"\n",
    "T = np.fromfile(T_dat, dtype=np.float64).reshape((n_i, n_j, n_k, n_n), order='F')\n",
    "sigma = compute_sigma(T=T)\n",
    "# sigma.flatten(order='F').tofile(\"sigma.dat\")\n",
    "\n",
    "# for test\n",
    "sigma_test = np.fromfile(\"/mnt/e/proj_yagi/s.dat\", dtype=np.float32).reshape((n_i, n_j, 9, n_n), order='F').astype(np.float64)\n",
    "display(np.mean(sigma[:,:,6,-1])) #,sigma_test[:,:,2,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess: T.dat -> dTdt.dat, dTdt.f -> dTdt.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script computes the temperature tendency (dT/dt) using a central difference scheme.\n",
    "\n",
    " - Input:\n",
    "    - temperature data from an unformatted binary file `T.dat` with dimensions (73, 37, 10, 20) stored in Fortran (column-major) order. \n",
    "\n",
    " -The tendency is computed for time indices 2 to 19 (i.e., using T(n+1) - T(n-1)) and the resulting array, with dimensions (73, 37, 10, 18) \n",
    "\n",
    " - Output:\n",
    "    -`dTdt.dat` in Fortran order.\n",
    "\n",
    "$$\n",
    "dTdt(i,j,k,n) = T(i,j,k,n+1) - T(i,j,k,n-1)\n",
    "$$\n",
    "== WHERE THE HECK IS 2*DELTA_T? =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#dTdt.py\n",
    "import numpy as np\n",
    "\n",
    "# Define the dimensions for temperature data T (73 x 37 x 10 x 20)\n",
    "n_i, n_j, n_k, n_n_T = 73, 37, 10, 20\n",
    "\n",
    "# Read temperature data from 'T.dat' (assumed to be Fortran-order unformatted binary file)\n",
    "T_dat = \"T.dat\"\n",
    "T = np.fromfile(T_dat, dtype=np.float64).reshape((n_i, n_j, n_k, n_n_T), order='F')\n",
    "\n",
    "def compute_dTdt(T:np.ndarray, delta_t:float=4.32e4, devide_by_dt:bool=False):\n",
    "    \"\"\"\n",
    "    Compute the dT (/dt) of a T field using central differences in time.\n",
    "    Parameters:\n",
    "    - T (numpy.ndarray): T field array with dimensions (n_i, n_j, n_k, n_n).\n",
    "    - delta_t (float): Time interval in seconds (default is 12 hours, 4.32e4 seconds).\n",
    "    - output_file (str): Name of the output file to save the computed tendency.\n",
    "    Returns:\n",
    "    - dTdt (numpy.ndarray): Computed dT/dt array with the same shape as the input data.\n",
    "    \"\"\"\n",
    "    # Initialize the tendency array with zeros\n",
    "    dTdt = np.zeros_like(T)\n",
    "    # Compute central difference in time for interior time steps\n",
    "    if not devide_by_dt:\n",
    "        dTdt[:, :, :, 1:-1] = (T[:, :, :, 2:] - T[:, :, :, :-2]) # / (2 * delta_t)\n",
    "    else: \n",
    "        dTdt[:, :, :, 1:-1] = (T[:, :, :, 2:] - T[:, :, :, :-2]) / (2 * delta_t)\n",
    "    # Write the computed tendency array to the specified output file in Fortran order\n",
    "    # tendency.flatten(order='F').tofile(output_file)\n",
    "    return dTdt\n",
    "\n",
    "# Compute dTdt for temperature data\n",
    "dTdt = compute_dTdt(T=T)\n",
    "dTdt.flatten(order=\"F\").tofile(\"dTdt.dat\")\n",
    "# For verification\n",
    "dTdt_test = np.fromfile(\"/mnt/e/proj_yagi/dTdt.dat\", dtype=np.float32).reshape((n_i, n_j, n_k, 19), order='F') # NOTE WHY the heck is 19?\n",
    "display(dTdt[4,5,:,6],dTdt_test[4,5,:,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess: sigma.dat -> mean_sigma.dat, areamean.f -> areamean.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This document explains the area-averaged variable calculation performed by the Python script (translated from `areamean.f`). It describes the input and output files, the formulas used in both continuous and discrete forms, and important notes regarding the computation and data handling.\n",
    "\n",
    "**Input Files**\n",
    "\n",
    "- **sigma.dat**  \n",
    "  An unformatted binary file containing the variable $ s $ with dimensions $73 \\times 37 \\times 9 \\times 20$.  \n",
    "  - Dimensions:  \n",
    "    - $i = 1, \\dots, 73$ (longitude)  \n",
    "    - $j = 1, \\dots, 37$ (latitude)  \n",
    "    - $k = 1, \\dots, 9$ (vertical levels)  \n",
    "    - $n = 1, \\dots, 20$ (time steps)  \n",
    "  - Data is stored in Fortran (column-major) order.\n",
    "\n",
    "**Output Files**\n",
    "\n",
    "- **areamean.dat**  \n",
    "  An unformatted binary file containing the computed area-averaged variable $ \\text{sm} $ with dimensions $9 \\times 20$ (vertical levels $\\times$ time steps), stored in Fortran order.\n",
    "\n",
    "**Formulas**\n",
    "\n",
    "Continuous Form\n",
    "\n",
    "In the continuous case, the area-averaged value of a variable $ s(\\phi) $ over a latitudinal band $[\\phi_1, \\phi_2]$ is defined as:\n",
    "\n",
    "$$\n",
    "\\bar{s} = \\frac{\\displaystyle \\int_{\\phi_1}^{\\phi_2} s(\\phi) \\cos(\\phi) \\, d\\phi}{\\displaystyle \\int_{\\phi_1}^{\\phi_2} \\cos(\\phi) \\, d\\phi},\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\phi$ is the latitude in radians.\n",
    "- $\\cos(\\phi)$ is the weighting factor due to the convergence of meridians.\n",
    "\n",
    "Discrete Form\n",
    "\n",
    "For a discrete grid with latitude spacing $\\Delta l$ (in radians) and grid points $j = 1, \\dots, 37$, the discrete area-averaged value for a given vertical level $k$ and time step $n$ is approximated by:\n",
    "\n",
    "$$\n",
    "\\text{sm}(k,n) \\approx \\frac{\\Delta l}{4 (ie - iw) \\left[\\sin\\left(\\Delta l \\, (jn-1)\\right) - \\sin\\left(\\Delta l \\, (js-1)\\right)\\right]} \\sum_{i=1}^{73} \\sum_{j=1}^{37} c_{ij} \\cos\\bigl((j-1)\\Delta l\\bigr)\\, s(i,j,k,n),\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ iw = 1 $ and $ ie = 73 $ (longitude boundaries),\n",
    "- $ js = 1 $ and $ jn = 37 $ (latitude boundaries),\n",
    "- $ c_{ij} $ is the weight at grid point $(i,j)$ defined as:\n",
    "  - $ c_{ij} = 1 $ for the four corner points,\n",
    "  - $ c_{ij} = 2 $ for edge points (excluding corners),\n",
    "  - $ c_{ij} = 4 $ for interior points.\n",
    "- $\\Delta l = \\frac{2.5\\pi}{180}$ is the grid spacing in radians.\n",
    "\n",
    "The normalization factor is given by:\n",
    "\n",
    "$$\n",
    "\\text{norm} = \\frac{\\Delta l}{4 (ie-iw) \\left[\\sin\\left(\\Delta l \\, (jn-1)\\right) - \\sin\\left(\\Delta l \\, (js-1)\\right)\\right]}.\n",
    "$$\n",
    "\n",
    "**Note**\n",
    "\n",
    "- **Weighting Scheme:**  \n",
    "  The weights $ c_{ij} $ (1 for corners, 2 for edges, 4 for interiors) approximate the area of each grid cell, similar to Simpson's rule in numerical integration.\n",
    "\n",
    "- **Latitude Weighting:**  \n",
    "  The factor $\\cos\\bigl((j-1)\\Delta l\\bigr)$ accounts for the decrease in zonal extent with increasing latitude.\n",
    "\n",
    "- **Data Ordering:**  \n",
    "  The input and output files are stored in Fortran (column-major) order. When using NumPy, ensure to reshape arrays with `order='F'` to maintain the correct data layout.\n",
    "\n",
    "- **Normalization:**  \n",
    "  The normalization factor ensures that the weighted sum is converted into an average over the specified domain.\n",
    "\n",
    "- **Units and Dimensions:**  \n",
    "  The grid spacing, domain boundaries, and dimensions are defined to match those in the original Fortran code. Ensure that these parameters are consistent with the data used in the calculation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# areamean.py\n",
    "# TODO improve integral method\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define dimensions (Fortran indices: i=1..73, j=1..37, k=1..9, n=1..20)\n",
    "n_i, n_j, n_k, n_n = 73, 37, 10, 20\n",
    "\n",
    "iw, ie, js, jn = 0, n_i, 0, n_j # west-east-south-north\n",
    "\n",
    "# Read the input array 'sigma' from the file 'sigma.dat' (Fortran order)\n",
    "sigma_file = 'sigma.dat'\n",
    "sigma = np.fromfile(sigma_file, dtype=np.float64).reshape((n_i, n_j, n_k, n_n), order='F')\n",
    "\n",
    "def compute_area_mean(variable:np.ndarray, iw=None, ie=None, js=None, jn=None, dl:float=2.5*np.pi/180, weights=None):\n",
    "    \"\"\"\n",
    "    Compute the area-averaged mean for a given variable.\n",
    "\n",
    "    Parameters:\n",
    "    - variable (numpy.ndarray): Input 4D array with dimensions (n_i, n_j, n_k, n_n).\n",
    "    - (iw, ie, js, jn): west:east, south:north indicates area, python slice form, default whole area\n",
    "    - dl (float): difference arc\n",
    "    - weights (numpy.ndarray, optional): Weight matrix with dimensions (n_i, n_j). If None, default weights are used.\n",
    "    Returns:\n",
    "    - numpy.ndarray: Area-averaged mean with dimensions (n_k, n_n).\n",
    "    \"\"\"\n",
    "    if iw and ie and js and jn:\n",
    "        variable = variable[iw:ie,js:jn,:,:]\n",
    "    else:\n",
    "        iw, js= 0, 0\n",
    "        ie, jn, n_k, n_n = variable.shape\n",
    "    # Define dimensions\n",
    "    n_i, n_j, n_k, n_n = variable.shape\n",
    "\n",
    "    # Create the weighting matrix W for spatial averaging if not provided\n",
    "    if weights is None:\n",
    "        # Default weight is 4.0\n",
    "        W = np.full((n_i, n_j), 4.0, dtype=np.float64)\n",
    "\n",
    "        # Set corner weights to 1.0\n",
    "        W[0, 0] = 1.0\n",
    "        W[0, -1] = 1.0\n",
    "        W[-1, 0] = 1.0\n",
    "        W[-1, -1] = 1.0\n",
    "\n",
    "        # Set edge weights (excluding corners) to 2.0\n",
    "        W[0, 1:-1] = 2.0\n",
    "        W[-1, 1:-1] = 2.0\n",
    "        W[1:-1, 0] = 2.0\n",
    "        W[1:-1, -1] = 2.0\n",
    "    else:\n",
    "        W = weights\n",
    "\n",
    "    # Compute latitude values for j=1,...,37. For Fortran, lat = (j-1)*dl.\n",
    "    lat_values = np.arange(js,jn) * dl  # shape (37,)\n",
    "    cos_lat = np.cos(lat_values)       # shape (37,)\n",
    "\n",
    "    # Multiply the weight matrix by the latitude-dependent cosine factor.\n",
    "    # Broadcasting: for each column j, multiply by cos(lat[j]).\n",
    "    W_final = W * cos_lat[np.newaxis, :]  # shape (73,37)\n",
    "\n",
    "    # Compute the area-averaged variable sm for each vertical level (k) and time step (n):\n",
    "    # sm(k,n) = sum_{i=1}^{73} sum_{j=1}^{37} [W_final(i,j) * variable(i,j,k,n)]\n",
    "    # Using tensordot to sum over the first two dimensions (i and j)\n",
    "    sm = np.tensordot(W_final, variable, axes=([0, 1], [0, 1]))  # resulting shape: (9, 20)\n",
    "\n",
    "    # Compute the normalization factor.\n",
    "    # In Fortran: norm = dl/(4*(ie-iw)*(sin(dl*(jn-1))-sin(dl*(js-1))))\n",
    "    # Here, iw=0, ie=73 so (ie-iw)-1=72, and js=0, jn=37 so (jn-1)=36 and sin(dl*0)=0.\n",
    "    norm = dl / (4.0 * (ie-iw-1) * (np.sin(dl * (jn-1)) - np.sin(dl*js)))\n",
    "\n",
    "    # Apply normalization to sm.\n",
    "    sm *= norm\n",
    "\n",
    "    return sm\n",
    "\n",
    "# Example usage:\n",
    "sigma_mean = compute_area_mean(sigma)\n",
    "\n",
    "# Write the computed sm to the output file 'areamean.dat' in Fortran (column-major) order.\n",
    "sigma_mean.flatten(order='F').tofile('sigma_mean.dat')\n",
    "\n",
    "sm_test = np.fromfile(\"/mnt/e/proj_yagi/areamean.dat\", dtype=np.float32).reshape((9,20), order='F')\n",
    "display(sigma_mean[:,-1],sm_test[:,-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intermedia $V_g \\cdot \\nabla T$: z.dat + T.dat-> T_g_adv.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Input Files:**  \n",
    "  - `z.dat`: Geopotential height data, dimensions $73 \\times 37 \\times 10 \\times 20$.  \n",
    "  - `T.dat`: Temperature data, dimensions $73 \\times 37 \\times 10 \\times 20$.\n",
    "\n",
    "- **Output File:**  \n",
    "  - `T_g_adv.dat`: Computed geostrophic temperature advection term, dimensions $73 \\times 37 \\times 10 \\times 20$.\n",
    "\n",
    "- **Formulas:**  \n",
    "  - **Continuous:**  \n",
    "    $$\n",
    "    \\text{adv} = \\frac{g}{f_0 \\cos(\\phi)} \\left( \\frac{\\partial z}{\\partial y} \\frac{\\partial T}{\\partial x} - \\frac{\\partial z}{\\partial x} \\frac{\\partial T}{\\partial y} \\right)\n",
    "    $$\n",
    "  - **Discrete:**  \n",
    "    $$\n",
    "    \\text{adv}(i,j,k,n) = \\frac{g}{f_0 \\cos(\\text{lat}) (2\\Delta l \\, a)^2} \\left[ \\bigl(z(i,j+1,k,n)-z(i,j-1,k,n)\\bigr)\\bigl(T(i+1,j,k,n)-T(i-1,j,k,n)\\bigr) - \\bigl(z(i+1,j,k,n)-z(i-1,j,k,n)\\bigr)\\bigl(T(i,j+1,k,n)-T(i,j-1,k,n)\\bigr) \\right].\n",
    "    $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# T_g_adv.py\n",
    "# TODO check delta_t\n",
    "import numpy as np\n",
    "\n",
    "def compute_T_g_adv(z:np.ndarray, T:np.ndarray, dl:float=(2.5*np.pi)/180.0):\n",
    "    \"\"\"\n",
    "    Compute the geostrophic temperature advection term.\n",
    "    Parameters:\n",
    "    - z (numpy.ndarray): Geopotential height field with dimensions (n_i, n_j, n_k, n_n).\n",
    "    - T (numpy.ndarray): Temperature field with dimensions (n_i, n_j, n_k, n_n).\n",
    "    - dl (float): Grid spacing in radians (default is 2.5 degrees in radians).\n",
    "    Returns:\n",
    "    - adv (numpy.ndarray): Computed geostrophic temperature advection term with the same dimensions as T.\n",
    "    \"\"\"\n",
    "    # Define constants\n",
    "    a = 6.37e6             # Earth radius in meters\n",
    "    f0 = 1.03124453e-4     # reference Coriolis parameter in 1/s\n",
    "    g = 9.81               # gravitational acceleration in m/s^2\n",
    "    # Initialize the advection array with zeros; same dimensions as T\n",
    "    adv = np.zeros_like(T, dtype=np.float64)\n",
    "    # Compute adv for interior grid points:\n",
    "    # Fortran loops: i = 2 to 72 and j = 2 to 36, which correspond to Python indices 1:-1 for i and 1:-1 for j.\n",
    "    # Compute central differences in the j-direction for z and T, and in the i-direction for T and z.\n",
    "    dZ_dj = z[1:-1, 2:, :, :] - z[1:-1, :-2, :, :]    # difference along j (latitude) for z\n",
    "    dT_di = T[2:, 1:-1, :, :] - T[:-2, 1:-1, :, :]    # difference along i (longitude) for T\n",
    "    dZ_di = z[2:, 1:-1, :, :] - z[:-2, 1:-1, :, :]    # difference along i for z\n",
    "    dT_dj = T[1:-1, 2:, :, :] - T[1:-1, :-2, :, :]    # difference along j for T\n",
    "    # Compute latitude for the interior j points.\n",
    "    # Fortran: j = 2 to 36, so lat = (j - 1) * dl, which gives values from 1*dl to 35*dl.\n",
    "    n_j = z.shape[1]\n",
    "    j_indices = np.arange(1, n_j - 1)  # indices 1 to 35 (Python)\n",
    "    lat = j_indices * dl              # shape (35,)\n",
    "    lat = lat.reshape(1, -1, 1, 1)    # reshape to (1, 35, 1, 1) for broadcasting\n",
    "    # Compute the latitude-dependent coefficient:\n",
    "    # coeff = g / (f0 * cos(lat) * (2 * dl * a)^2)\n",
    "    coeff = g / (f0 * np.cos(lat) * (2 * dl * a)**2)\n",
    "    # Calculate the advection term for interior points using the vectorized expression:\n",
    "    # adv(i,j,k,n) = (g/(f0*cos(lat)*(2*dl*a)**2)) * { [z(i,j+1,k,n)-z(i,j-1,k,n)]*[T(i+1,j,k,n)-T(i-1,j,k,n)]\n",
    "    #                                           - [z(i+1,j,k,n)-z(i-1,j,k,n)]*[T(i,j+1,k,n)-T(i,j-1,k,n)] }\n",
    "    adv_interior = coeff * ((dZ_dj * dT_di) - (dZ_di * dT_dj))\n",
    "    # Place the computed interior values into the full adv array.\n",
    "    adv[1:-1, 1:-1, :, :] = adv_interior\n",
    "    return adv\n",
    "\n",
    "# Define dimensions\n",
    "n_i, n_j, n_k, n_n = 73, 37, 10, 20\n",
    "# Read potential height and temperature data from files\n",
    "z_dat = \"z.dat\"\n",
    "T_dat = \"T.dat\"\n",
    "try:\n",
    "    z = np.fromfile(z_dat, dtype=np.float64).reshape((n_i, n_j, n_k, n_n), order='F')\n",
    "    T = np.fromfile(T_dat, dtype=np.float64).reshape((n_i, n_j, n_k, n_n), order='F')\n",
    "except Exception as e:\n",
    "    raise IOError(\"Error reading input files: \" + str(e))\n",
    "\n",
    "\n",
    "# Call the function\n",
    "adv = compute_T_g_adv(z, T)\n",
    "\n",
    "# Write the computed advection term to 'T_g_adv.dat' in Fortran (column-major) order.\n",
    "adv.flatten(order='F').tofile('T_g_adv.dat')\n",
    "\n",
    "# For verification, print the values of adv at grid point (42,18,k,4) for all vertical levels.\n",
    "# Fortran indices (42,18,k,4) correspond to Python indices (41,17,:,3).\n",
    "# print(\"adv(42,18,k,4) for k=1,...,10:\")\n",
    "# print(adv[41, 17, :, 3])\n",
    "adv_test = np.fromfile(\"/mnt/e/proj_yagi/T_g_adv.dat\", dtype=np.float32).reshape((n_i, n_j, n_k, n_n), order='F')\n",
    "display(adv[41, 17, :, 3],adv_test[41, 17, :, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forcing: residue.f -> residue.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Overview**\n",
    "\n",
    "This document describes the calculation of the residual term $R$ in the thermal energy equation. The residual is computed by combining the temperature tendency, geostrophic temperature advection, and a vertical component involving the vertical velocity, residual thermal energy field, and pressure. The Python code (translated from `residue.f`) reads several input binary files (stored in Fortran column-major order), computes the residual using a discrete formulation, and writes the result to an output file.\n",
    "\n",
    "\n",
    "**Input Files**\n",
    "\n",
    "- **dTdt.dat**  \n",
    "  Unformatted binary file containing the temperature tendency data $\\text{dTdt}$ with dimensions:\n",
    "  - $73 \\times 37 \\times 10 \\times 19$  \n",
    "    (longitude $\\times$ latitude $\\times$ vertical levels $\\times$ time steps)\n",
    "\n",
    "- **T_g_adv.dat**  \n",
    "  Unformatted binary file containing the geostrophic temperature advection data $\\text{adv}$ with dimensions:\n",
    "  - $73 \\times 37 \\times 10 \\times 20$\n",
    "\n",
    "- **omega.dat**  \n",
    "  Unformatted binary file containing the vertical velocity data $\\omega$ with dimensions:\n",
    "  - $73 \\times 37 \\times 10 \\times 20$\n",
    "\n",
    "- **s.dat**  \n",
    "  Unformatted binary file containing the residual thermal energy field $s$ with dimensions:\n",
    "  - $73 \\times 37 \\times 9 \\times 20$\n",
    "\n",
    "\n",
    "\n",
    "**Output File**\n",
    "\n",
    "- **residue.dat**  \n",
    "  Unformatted binary file (stored in Fortran column-major order) containing the computed residual $R$.  \n",
    "  Dimensions: $73 \\times 37 \\times 9 \\times 18$  \n",
    "  (Note: The computation is performed for time steps $n = 2$ to $n = 19$ in Fortran, resulting in 18 time steps.)\n",
    "\n",
    "\n",
    "\n",
    "**Formulas**\n",
    "\n",
    "**Continuous Form**\n",
    "\n",
    "In a continuous framework, the residual $R$ of the thermal energy equation can be expressed as:\n",
    "\n",
    "$$\n",
    "R = 1/C_p \\frac{dH}{dt} = \\frac{dT}{dt} + V_g\\cdot \\nabla T  - \\omega \\sigma \\frac{p}{R_d}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\frac{dT}{dt}$ is the time derivative of temperature,\n",
    "- $T_{\\text{adv}}$ represents the temperature advection,\n",
    "- $\\omega$ is the vertical velocity,\n",
    "- $sigma$ is the static field,\n",
    "- $p$ is the pressure,\n",
    "- $\\Delta t$ is the time interval (12 hours, i.e., $4.32 \\times 10^4$ seconds),\n",
    "- $\\rho$ is a reference density (here represented by 287, the gas constant for dry air),\n",
    "- $R_d$: dry air gas const, $C_p$: specific heat capacity of air at const pressure.\n",
    "\n",
    "**Discrete Form**\n",
    "\n",
    "In the discrete implementation (as in the Fortran code), the residual $R(i,j,k,n)$ is computed using:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "R(i,j,k,n) &= \\text{dTdt}(i,j,k,n) - 4.32\\times10^4\\, \\text{adv}(i,j,k,n) \\\\\n",
    "           &\\quad - \\; 4.32\\times10^4 \\times 0.01 \\times \\frac{\\omega(i,j,k,n) \\, sigma(i,j,k,n) \\, p(k)}{287}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\text{dTdt}(i,j,k,n)$ is the temperature tendency at grid point $(i,j,k)$ and time step $n$,\n",
    "- $\\text{adv}(i,j,k,n)$ is the geostrophic temperature advection at that grid point,\n",
    "- $\\omega(i,j,k,n)$ is the vertical velocity,\n",
    "- $sigma(i,j,k,n)$ is the static field,\n",
    "- $p(k)$ is the pressure at the $k$-th level,\n",
    "- The constant $4.32\\times10^4$ (in seconds) represents the 12-hour time interval,\n",
    "- The factor $0.01$ is an empirical scaling factor,\n",
    "- Division by 287 converts the units appropriately (since 287 J/(kg·K) is the gas constant for dry air).\n",
    "\n",
    "\n",
    "**Note**\n",
    "\n",
    "- **Data Ordering:**  \n",
    "  All files are stored in Fortran (column-major) order. When reading or writing files using NumPy, make sure to use `order='F'` when reshaping or flattening arrays.\n",
    "\n",
    "- **Time Interval:**  \n",
    "  The constant $4.32 \\times 10^4$ seconds corresponds to a 12-hour period and is used to scale the advection and vertical terms appropriately.\n",
    "\n",
    "- **Scaling Factors:**  \n",
    "  The multiplication by $0.01$ and division by 287 are used to adjust the units and scale the vertical contribution.\n",
    "\n",
    "- **Grid and Dimensions:**  \n",
    "  The computation is performed over:\n",
    "  - Longitude indices: $i = 1, \\dots, 73$\n",
    "  - Latitude indices: $j = 1, \\dots, 37$\n",
    "  - Vertical levels: $k = 1, \\dots, 9$ (from the `s` array)\n",
    "  - Time steps: $n = 2, \\dots, 19$ (resulting in 18 time steps in the residual computation)\n",
    "\n",
    "- **Units:**  \n",
    "  The computed residual $R$ is expressed in units of Kelvin per 12 hours (K/12hr).\n",
    "\n",
    "- **Empirical Nature:**  \n",
    "  The formulation includes empirical scaling factors (such as 0.01) that may be adjusted based on model calibration or specific study requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# residue.f\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# dimensions for arrarys\n",
    "n_i, n_j, n_k, n_n = 73, 37, 10, 20\n",
    "\n",
    "datatype = np.float64\n",
    "\n",
    "# Read input files (assumed to be Fortran-ordered unformatted binary files)\n",
    "dTdt = np.fromfile('dTdt.dat', dtype=datatype).reshape((n_i, n_j, n_k, n_n), order='F')\n",
    "adv = np.fromfile('T_g_adv.dat', dtype=datatype).reshape((n_i, n_j, n_k, n_n), order='F')\n",
    "omega = np.fromfile('omega.dat', dtype=datatype).reshape((n_i, n_j, n_k, n_n), order='F')\n",
    "sigma = np.fromfile('sigma.dat', dtype=datatype).reshape((n_i, n_j, n_k, n_n), order='F')\n",
    "\n",
    "def compute_residual(dTdt:np.ndarray, adv:np.ndarray, omega:np.ndarray, sigma:np.ndarray, p:np.ndarray=np.array([1000., 925., 850., 700., 600., 500., 400., 300., 200., 100.], dtype=np.float64)):\n",
    "    \"\"\"\n",
    "    Compute the residual R using the provided inputs.\n",
    "\n",
    "    Parameters:\n",
    "    - dTdt (numpy.ndarray): Temperature tendency array with dimensions (n_i, n_j, n_k, n_n).\n",
    "    - adv (numpy.ndarray): Geostrophic temperature advection array with dimensions (n_i, n_j, n_k, n_n).\n",
    "    - omega (numpy.ndarray): Vertical velocity array with dimensions (n_i, n_j, n_k, n_n).\n",
    "    - sigma (numpy.ndarray): Static stability parameter array with dimensions (n_i, n_j, n_k, n_n).\n",
    "    - p (numpy.ndarray): Pressure levels in hPa (default: [1000, 925, 850, 700, 600, 500, 400, 300, 200, 100]).\n",
    "\n",
    "    Returns:\n",
    "    - R (numpy.ndarray): Residual array with dimensions (n_i, n_j, n_k, n_n).\n",
    "    \"\"\"\n",
    "    # Reshape pressure levels for broadcasting along (i, j, n) dimensions\n",
    "    p_reshaped = p.reshape(1, 1, len(p), 1)\n",
    "\n",
    "    # Constants\n",
    "    delta_t = 4.32e4  # 12 hours in seconds\n",
    "    dry_gas_const = 287.052874  # Dry air gas constant\n",
    "\n",
    "    # Compute the residual R using vectorized operations\n",
    "    R = dTdt - (adv * delta_t) - (delta_t * 0.01 * omega * sigma * p_reshaped) / dry_gas_const\n",
    "\n",
    "    return R\n",
    "\n",
    "R = compute_residual(dTdt,adv,omega,sigma)\n",
    "# Write the computed residual R to 'residue.dat' in Fortran order.\n",
    "R.flatten(order='F').tofile('residue.dat')\n",
    "\n",
    "R_test = np.fromfile('/mnt/e/proj_yagi/residue.dat', dtype=np.float32).reshape((n_i, n_j, 9, 19), order='F')\n",
    "display(R[41, 17, :, 3],R_test[41, 17, :, 3]) # NOTE the slight difference comes from dry air const"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result: omega_D.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "\n",
    "This document describes the computation of a relaxed vertical velocity field (\"omega\") using an iterative relaxation scheme. The method adjusts an initial omega field by incorporating a forcing term derived from a residual field and an area-mean field. The iteration proceeds until the maximum update is below 0.1 μb/s (1e-3 mb/s). This procedure is implemented in a fully vectorized Python code using NumPy.\n",
    "\n",
    "**Input Files**\n",
    "\n",
    "- **residue.dat**  \n",
    "  An unformatted binary file (stored in Fortran column-major order) containing the residual field `res` with dimensions:  \n",
    "  $$\n",
    "  (73 \\times 37 \\times 9 \\times 19)\n",
    "  $$\n",
    "  This field is obtained from previous thermal energy calculations.\n",
    "\n",
    "- **areamean.dat**  \n",
    "  An unformatted binary file (stored in Fortran column-major order) containing the area-mean field `s` with dimensions:  \n",
    "  $$\n",
    "  (9 \\times 20)\n",
    "  $$\n",
    "  This field is used to scale the forcing in the relaxation process.\n",
    "\n",
    "**Output File**\n",
    "\n",
    "- **omega_D.dat**  \n",
    "  An unformatted binary file (stored in Fortran column-major order) containing the relaxed vertical velocity field `w` with dimensions:  \n",
    "  $$\n",
    "  (73 \\times 37 \\times 9 \\times 20)\n",
    "  $$\n",
    "  The units of `w` are 1e-3 mb/s (μb/s).\n",
    "\n",
    "**Formulas**\n",
    "\n",
    "**Continuous Form**\n",
    "\n",
    "In a continuous framework, the evolution of the vertical velocity field $\\omega $(in response to a forcing $F $and diffusion-like processes) can be expressed as:\n",
    "$$\n",
    "\\frac{\\partial \\omega}{\\partial t} = -F + \\mathcal{L}(\\omega),\n",
    "$$\n",
    "where $\\mathcal{L}(\\omega) $includes the horizontal Laplacian and vertical coupling of $\\omega $.\n",
    "\n",
    "**Discrete Form**\n",
    "\n",
    "The discrete update used in the relaxation process is:\n",
    "$$\n",
    "\\omega_{\\text{new}}(i,j,k,n) = \\omega(i,j,k,n) + \\frac{R_i}{\\text{denom}},\n",
    "$$\n",
    "with\n",
    "$$\n",
    "R_i = \\frac{\\omega(i+1,j,k,n) - 2\\,\\omega(i,j,k,n) + \\omega(i-1,j,k,n)}{(a\\,dl\\,\\cos(\\text{lat}))^2} - \\tan(\\text{lat})\\,\\frac{\\omega(i,j+1,k,n)-\\omega(i,j-1,k,n)}{2\\,dl\\,a^2} + \\frac{\\omega(i,j+1,k,n) - 2\\,\\omega(i,j,k,n) + \\omega(i,j-1,k,n)}{(a\\,dl)^2} + \\frac{f_0^2}{s(k,n)}\\frac{\\alpha\\,\\omega(i,j,k-1,n)-\\beta\\,\\omega(i,j,k,n)+\\gamma\\,\\omega(i,j,k+1,n)}{dp1\\,dp2} - F(i,j,k,n)\n",
    "$$\n",
    "and the coefficients:\n",
    "$$\n",
    "\\alpha = \\frac{dp2}{2\\,dp1}+0.5,\\quad \\beta = \\frac{dp2}{2\\,dp1} + \\frac{dp1}{2\\,dp2} + 1.0,\\quad \\gamma = \\frac{dp1}{2\\,dp2}+0.5,\n",
    "$$\n",
    "where\n",
    "$$\n",
    "dp1 = p(k-1) - p(k), \\quad dp2 = p(k) - p(k+1).\n",
    "$$\n",
    "The denominator normalizes the update:\n",
    "$$\n",
    "\\text{denom} = \\frac{2}{(a\\,dl\\,\\cos(\\text{lat}))^2} + \\frac{2}{(a\\,dl)^2} + \\frac{f_0^2}{s(k,n)}\\frac{\\alpha + \\gamma - 1}{dp1\\,dp2}.\n",
    "$$\n",
    "\n",
    "**Notes on the Discrete Form**\n",
    "\n",
    "- **Spatial Differencing:**  \n",
    "  The horizontal derivatives are approximated using central differences. The grid spacing is given by $dl = \\frac{2.5\\pi}{180}$(in radians) and the physical distance is $a \\cdot dl $(with $a = 6.37 \\times 10^6 $m, the Earth's radius).\n",
    "\n",
    "- **Vertical Coupling:**  \n",
    "  The vertical differences use central differencing with the pressure differences $dp1$and $dp2$to couple adjacent vertical levels.\n",
    "\n",
    "- **Forcing Term and Unit Conversion:**  \n",
    "  The forcing term $F$is scaled by $-\\frac{1000}{4.32 \\times 10^4}$and divided by $p(k)\\, s(k,n)$(with additional factors) to convert the units appropriately, resulting in an omega field in μb/s.\n",
    "\n",
    "**Note**\n",
    "\n",
    "- **Data Ordering:**  \n",
    "  The input and output files are in Fortran column-major order. Use `order='F'` when reshaping or flattening arrays in NumPy to maintain the correct layout.\n",
    "\n",
    "- **Grid and Domain:**  \n",
    "  The grid dimensions are:  \n",
    "  - 73 points in the longitudinal direction (i)\n",
    "  - 37 points in the latitudinal direction (j)\n",
    "  - 9 vertical levels (k)\n",
    "  - Forcing is computed over 19 time steps (n) and omega is defined for 20 time steps (with relaxation applied over the first 19)\n",
    "\n",
    "- **Pressure Levels:**  \n",
    "  The pressure levels are defined as:  \n",
    "  $[1000, 925, 850, 700, 600, 500, 400, 300, 200, 100]$hPa.\n",
    "\n",
    "- **Convergence Criteria:**  \n",
    "  The iterative relaxation of $\\omega $continues until the maximum absolute update in the interior grid is less than 0.1 μb/s.\n",
    "\n",
    "- **Vectorization:**  \n",
    "  The code is fully vectorized over the horizontal, vertical, and time dimensions to improve performance, avoiding explicit loops where possible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define constants\n",
    "pi = np.pi\n",
    "a = 6.371e6\n",
    "f0 = 1.03124453e-4\n",
    "g = 9.81\n",
    "r = 287.052874\n",
    "\n",
    "# Pressure levels (hPa)\n",
    "p_default = np.array([1000., 925., 850., 700., 600., 500., 400., 300., 200., 100.], dtype=np.float64)\n",
    "dl_default = 2.5 * pi / 180.0  # Default latitude differential\n",
    "\n",
    "def compute_diabatic_forcing(res, sm, p=p_default, dl=dl_default, iw=1, ie=72, js=1, jn=36):\n",
    "    \"\"\"\n",
    "    Compute the Forcing Term F over the interior region using the given residue and sigma mean arrays.\n",
    "    \n",
    "    Parameters:\n",
    "        res (np.ndarray): The residue array, should have shape (n_i, n_j, n_k, n_n)\n",
    "        sm (np.ndarray): The sigma mean array, should have shape (n_k, n_n)\n",
    "        p (np.ndarray): The array of pressure levels (default: standard pressure levels)\n",
    "        dl (float): Latitude differential (default: 2.5*pi/180.0)\n",
    "        iw, ie, js, jn (int): The boundary indices for the interior region (default: 1, 72, 1, 36)\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: The computed forcing term F with shape (n_i, n_j, n_k, n_n)\n",
    "    \"\"\"\n",
    "    # Define constants\n",
    "    pi = np.pi\n",
    "    a = 6.371e6\n",
    "    f0 = 1.03124453e-4\n",
    "    g = 9.81\n",
    "    r = 287.052874\n",
    "    n_i, n_j, n_k, n_n = res.shape\n",
    "    \n",
    "    # Extract slices from \"res\"\n",
    "    I = slice(iw, ie)  # i indices\n",
    "    J = slice(js, jn)  # j indices\n",
    "    K = slice(1, n_k-1)  # k indices\n",
    "    N = slice(0, n_n)  # n indices\n",
    "    \n",
    "    res_center = res[I, J, K, N]\n",
    "    res_ip = res[2:ie+1, J, K, N]  # i+1\n",
    "    res_im = res[0:ie-1, J, K, N]  # i-1\n",
    "    res_jp = res[I, 2:jn+1, K, N]  # j+1\n",
    "    res_jm = res[I, 0:jn-1, K, N]  # j-1\n",
    "\n",
    "    # Compute latitude for interior j indices\n",
    "    j_indices = np.arange(js, jn)  # shape (34,)\n",
    "    lat = j_indices * dl  # shape (34,)\n",
    "    cos_lat = np.cos(lat).reshape(1, jn-js, 1, 1)\n",
    "    tan_lat = np.tan(lat).reshape(1, jn-js, 1, 1)\n",
    "\n",
    "    # Finite differences for horizontal derivatives:\n",
    "    term1 = (res_ip - 2 * res_center + res_im) / ((a * dl * cos_lat) ** 2)\n",
    "    term2 = (res_jp - 2 * res_center + res_jm) / ((a * dl) ** 2)\n",
    "    term3 = (tan_lat / (2 * dl * a ** 2)) * (res_jp - res_jm)\n",
    "\n",
    "    # For each interior vertical level, compute dp1 and dp2:\n",
    "    dp1_vec = p[0:n_k-2] - p[K]  # shape (8,)\n",
    "    dp2_vec = p[K] - p[2:n_k]  # shape (8,)\n",
    "    dp1_b = dp1_vec.reshape(1, 1, n_k-2, 1)  # broadcast to shape (1,1,8,1)\n",
    "    dp2_b = dp2_vec.reshape(1, 1, n_k-2, 1)\n",
    "\n",
    "    # Get s values for interior k and time steps\n",
    "    s_interior = sm[K, N]  # shape (8, 19)\n",
    "    s_b = s_interior.reshape(1, 1, n_k-2, n_n)  # shape (1,1,8,19)\n",
    "\n",
    "    # Compute fac (forcing factor); note the empirical factor 1000 for unit conversion.\n",
    "    p_interior = p[K].reshape(n_k-2, 1)  # shape (8,1)\n",
    "    fac = -(1000 / 4.32e4) * (r / (p_interior * s_interior))  # shape (8,19)\n",
    "    fac = fac.reshape(1, 1, n_k-2, n_n)  # reshape to (1,1,8,19)\n",
    "\n",
    "    # Compute F in the interior region:\n",
    "    F_interior = fac * (term1 + term2 - term3)  # shape (71,35,8,19)\n",
    "\n",
    "    # Allocate full F array and insert computed interior values\n",
    "    F = np.zeros((n_i, n_j, n_k, n_n), dtype=np.float64)\n",
    "    F[I, J, K, N] = F_interior\n",
    "\n",
    "    return F\n",
    "\n",
    "def relax_omega_field(F, w, sm, tolerance=0.001 , max_iter=20000 , p=p_default, dl=dl_default, iw=1, ie=72, js=1, jn=36):\n",
    "    \"\"\"\n",
    "    Perform relaxation iteration for the omega field using the given forcing term and initial omega field.\n",
    "    \n",
    "    Parameters:\n",
    "        F (np.ndarray): The forcing term array, should have shape (n_i, n_j, n_k, n_n)\n",
    "        w (np.ndarray): The initial omega field array, should have shape (n_i, n_j, n_k, n_n)\n",
    "        sm (np.ndarray): The sigma mean array, should have shape (n_k, n_n)\n",
    "        p (np.ndarray): The array of pressure levels (default: standard pressure levels)\n",
    "        dl (float): Latitude differential (default: 2.5*pi/180.0)\n",
    "        iw, ie, js, jn (int): The boundary indices for the interior region (default: 1, 72, 1, 36)\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: The updated omega field w after relaxation iterations\n",
    "    \"\"\"\n",
    "    # Define constants\n",
    "    pi = np.pi\n",
    "    a = 6.371e6\n",
    "    f0 = 1.03124453e-4\n",
    "    g = 9.81\n",
    "    r = 287.052874\n",
    "    n_i, n_j, n_k, n_n = w.shape  # Recompute dimensions for omega field\n",
    "\n",
    "    for m in range(max_iter):\n",
    "        # Extract interior region of w for current iteration:\n",
    "        I = slice(iw, ie)  # i indices\n",
    "        J = slice(js, jn)  # j indices\n",
    "        K = slice(1, n_k-1)  # k indices\n",
    "        N = slice(0, n_n)  # n indices\n",
    "\n",
    "        w_center = w[I, J, K, N]  # shape: (71, 35, 8, 19)\n",
    "        w_ip = w[2:n_i, J, K, N]\n",
    "        w_im = w[0:n_i-2, J, K, N]\n",
    "        w_jp = w[I, 2:n_j, K, N]\n",
    "        w_jm = w[I, 0:n_j-2, K, N]\n",
    "\n",
    "        # Horizontal second derivatives\n",
    "        d2w_di2 = (w_ip - 2 * w_center + w_im) / ((a * dl * np.cos(np.arange(js, jn) * dl).reshape(1, jn-js, 1, 1)) ** 2)\n",
    "        d2w_dj2 = (w_jp - 2 * w_center + w_jm) / ((a * dl) ** 2)\n",
    "        dw_dj = (w_jp - w_jm) / (2 * dl * a**2)\n",
    "\n",
    "        # Vertical neighbors for interior: \n",
    "        w_km = w[I, J, 0:n_k-2, N]  # shape: (71, 35, 7, 19)\n",
    "        w_kp = w[I, J, 2:n_k, N]  # shape: (71, 35, 7, 19)\n",
    "\n",
    "        # Compute vertical coupling term (fully vectorized)\n",
    "        dp1_b_relax = (p[0:(n_k-2)] - p[K]).reshape(1, 1, n_k-2, 1)  # shape (1,1,8,1)\n",
    "        dp2_b_relax = (p[K] - p[2:n_k]).reshape(1, 1, n_k-2, 1)  # shape (1,1,8,1)\n",
    "        s_b = sm[K, N].reshape(1, 1, n_k-2, n_n)  # shape (1,1,8,19)\n",
    "\n",
    "        d2w_dp2 = ((dp2_b_relax / (2 * dp1_b_relax) + 0.5) * w_km -\n",
    "                   (dp2_b_relax / (2 * dp1_b_relax) + dp1_b_relax / (2 * dp2_b_relax) + 1.0) * w_center +\n",
    "                   (dp1_b_relax / (2 * dp2_b_relax) + 0.5) * w_kp) / (dp1_b_relax * dp2_b_relax)\n",
    "\n",
    "        # Extract F for the interior region from F (using same slices as in relaxation)\n",
    "        F_interior = F[I, J, K, N]\n",
    "\n",
    "        # Compute relaxation update Ri (vectorized over i, j, k, n)\n",
    "        Ri = (d2w_di2 - np.tan(np.arange(js, jn) * dl).reshape(1, jn-js, 1, 1) * dw_dj +\n",
    "              d2w_dj2 + (f0**2 / s_b) * d2w_dp2 - F_interior)\n",
    "\n",
    "        # Compute denominator\n",
    "        denom = (2 / ((a * dl * np.cos(np.arange(js, jn) * dl).reshape(1, jn-js, 1, 1)) ** 2) +\n",
    "                 2 / ((a * dl) ** 2) +\n",
    "                 (f0**2 / s_b) * (dp2_b_relax / (2 * dp1_b_relax) + dp1_b_relax / (2 * dp2_b_relax) + 1.0) / (dp1_b_relax * dp2_b_relax))\n",
    "\n",
    "        c_update = Ri / denom\n",
    "        w[I, J, K, N] += c_update\n",
    "\n",
    "        absmax = np.max(np.abs(c_update))\n",
    "        if absmax < tolerance:\n",
    "            break\n",
    "\n",
    "    return w\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Assume you have preloaded `res` and `sm` arrays from files\n",
    "    res = np.fromfile(\"residue.dat\", dtype=np.float64).reshape((73, 37, 10, 20), order=\"F\")\n",
    "    sm = np.fromfile(\"sigma_mean.dat\", dtype=np.float64).reshape((10, 20), order=\"F\")\n",
    "    \n",
    "    # Compute Forcing Term F\n",
    "    F = compute_diabatic_forcing(res, sm)\n",
    "    \n",
    "    # Initialize omega field w (could be zeros or some initial guess)\n",
    "    w_initial = np.zeros_like(res)\n",
    "    \n",
    "    # Relax omega field\n",
    "    w_relaxed = relax_omega_field(F, w_initial, sm)\n",
    "    \n",
    "    # Optionally, write the output to file\n",
    "    w_relaxed.flatten(order=\"F\").tofile(\"omega_D.dat\")\n",
    "w_test = np.fromfile(\"/mnt/e/proj_yagi/omega_D.dat\", dtype=np.float32).reshape((73,37,9,20), order=\"F\")\n",
    "display(w_relaxed[30,10,:,10],w_test[30,10,:,10])\n",
    "display(np.max(np.abs(w_relaxed[:,:,:-1,1:-1]-w_test[:,:,:,1:-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorticity (Machanism) forced omega: omega_V.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Dependency Tree：\n",
    "omega_vort_g_adv.dat\n",
    "    └── relax_omega_vort_g_adv.f\n",
    "        ├── areamean.dat\n",
    "        │   └── areamean.f\n",
    "        │       └── s.dat\n",
    "        │           └── static.f\n",
    "        │               └── T.dat\n",
    "        └── vort_g_adv.dat\n",
    "            └── vort_g_adv.f\n",
    "                ├── eta_g.dat\n",
    "                │   └── vort_g.f\n",
    "                │       └── z.dat\n",
    "                └── z.dat\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess: z.dat -> zetag.dat & etag.dat, vort_g.f -> vort_g.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "\n",
    "This document describes the computation of geostrophic relative and absolute vorticity fields from a geopotential height field. The original Fortran program (`vort_g.f`) has been translated into Python using NumPy for full vectorization. The Python script reads the geopotential height from an input file, computes the relative vorticity (zetag) and absolute vorticity (etag) using central finite differences, and writes the results to separate output files.\n",
    "\n",
    "**Input File**\n",
    "\n",
    "- **z.dat**  \n",
    "  - **Description:** An unformatted binary file containing the geopotential height field `z`.\n",
    "  - **Dimensions:** 73 (longitude) × 37 (latitude) × 10 (vertical levels) × 20 (time steps)\n",
    "  - **Data Order:** Fortran (column-major) order\n",
    "\n",
    "**Output Files**\n",
    "\n",
    "- **zeta_g.dat**  \n",
    "  - **Description:** An unformatted binary file containing the geostrophic relative vorticity field (`zetag`).\n",
    "  - **Dimensions:** 73 × 37 × 10 × 20  \n",
    "  - **Data Order:** Fortran order\n",
    "\n",
    "- **eta_g.dat**  \n",
    "  - **Description:** An unformatted binary file containing the geostrophic absolute vorticity field (`etag`).\n",
    "  - **Dimensions:** 73 × 37 × 10 × 20  \n",
    "  - **Data Order:** Fortran order\n",
    "\n",
    "**Mathematical Formulas**\n",
    "\n",
    "**Continuous Form**\n",
    "\n",
    "1. **Geostrophic Relative Vorticity ($\\zeta_g$)**\n",
    "\n",
    "   The geostrophic relative vorticity is defined as:\n",
    "   $$\n",
    "   \\zeta_g = \\frac{g}{f_0} \\left( \\frac{\\partial^2 z}{\\partial x^2} + \\frac{\\partial^2 z}{\\partial y^2} - \\tan(\\phi) \\frac{\\partial z}{\\partial y} \\frac{1}{2a^2\\,dl} \\right)\n",
    "   $$\n",
    "   where:\n",
    "   - $g$ is the gravitational acceleration (9.81 m/s²)\n",
    "   - $f_0$ is the reference Coriolis parameter (1.03124453×10⁻⁴ s⁻¹)\n",
    "   - $z$ is the geopotential height\n",
    "   - $\\phi$ is the latitude, defined as $\\phi = (j-1)\\,dl$ (in radians)\n",
    "   - $a$ is the Earth's radius (6.37×10⁶ m)\n",
    "   - $dl$ is the grid spacing in radians (2.5° converted to radians)\n",
    "\n",
    "2. **Geostrophic Absolute Vorticity ($\\eta_g$)**\n",
    "\n",
    "   The geostrophic absolute vorticity adds the planetary vorticity to the relative vorticity:\n",
    "   $$\n",
    "   \\eta_g = \\zeta_g + 2\\,\\omega \\sin(\\phi)\n",
    "   $$\n",
    "   where:\n",
    "   - $\\omega$ is the Earth's angular velocity (7.292×10⁻⁵ s⁻¹)\n",
    "   - $\\sin(\\phi)$ accounts for the variation with latitude\n",
    "\n",
    "**Discrete Form**\n",
    "\n",
    "Using central finite differences, the discrete formulas for interior grid points are:\n",
    "\n",
    "1. **Relative Vorticity ($\\zeta_g$):**\n",
    "\n",
    "   $$\n",
    "   \\zeta_g(i,j,k,n) = \\frac{g}{f_0} \\left[\n",
    "   \\frac{z(i+1,j,k,n) - 2\\,z(i,j,k,n) + z(i-1,j,k,n)}{(a\\,dl\\,\\cos(\\phi))^2} +\n",
    "   \\frac{z(i,j+1,k,n) - 2\\,z(i,j,k,n) + z(i,j-1,k,n)}{(a\\,dl)^2} -\n",
    "   \\frac{\\tan(\\phi)}{2\\,dl\\,a^2}\\left(z(i,j+1,k,n) - z(i,j-1,k,n)\\right)\n",
    "   \\right]\n",
    "   $$\n",
    "   where $\\phi = (j-1) \\, dl$ for the interior grid (Fortran indices $j=2$ to $36$).\n",
    "\n",
    "2. **Absolute Vorticity ($\\eta_g$):**\n",
    "\n",
    "   $$\n",
    "   \\eta_g(i,j,k,n) = \\zeta_g(i,j,k,n) + 2\\,\\omega\\,\\sin(\\phi)\n",
    "   $$\n",
    "\n",
    "   The above formulas are computed for all interior grid points where the necessary neighbors exist (i.e., $i=2\\ldots72$ and $j=2\\ldots36$); the vertical (k) and time (n) dimensions are processed fully.\n",
    "\n",
    "**Note**\n",
    "\n",
    "- **Data Ordering:**  \n",
    "  All input and output files are in Fortran column-major order. When using NumPy, ensure to reshape or flatten arrays using `order=\"F\"`.\n",
    "\n",
    "- **Grid Boundaries:**  \n",
    "  The finite difference approximations are applied only to interior grid points (e.g., $i=2\\ldots72$ and $j=2\\ldots36$) to guarantee that both forward and backward differences are available.\n",
    "\n",
    "- **Latitude Dependence:**  \n",
    "  The latitude $\\phi$ is computed as $\\phi = (j-1)\\,dl$, where $dl$ is in radians. This factor is used in the cosine, tangent, and sine terms to correctly weight the spatial derivatives.\n",
    "\n",
    "- **Physical Constants:**  \n",
    "  The constants $g$, $f_0$, $a$, and $\\omega$ are taken from standard atmospheric values and are used to scale the computed vorticity appropriately.\n",
    "\n",
    "- **Vectorization:**  \n",
    "  The Python implementation uses NumPy vectorized operations to compute finite differences over the entire grid simultaneously, which greatly improves performance compared to explicit loops.\n",
    "\n",
    "**Usage**\n",
    "\n",
    "1. **Input Preparation:**  \n",
    "   Ensure that the input file `z.dat` is available in the working directory with the correct dimensions (73×37×10×20) and Fortran order.\n",
    "\n",
    "2. **Execution:**  \n",
    "   Run the Python script. The script reads `z.dat`, computes `zetag` and `etag`, writes the results to `zeta_g.dat` and `eta_g.dat` respectively, and prints diagnostic values for a sample grid point.\n",
    "\n",
    "3. **Output:**  \n",
    "   The resulting vorticity fields are saved in Fortran order, and you may use these files in subsequent model diagnostics or visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# vort_g.py\n",
    "import numpy as np\n",
    "\n",
    "def compute_vorticity(z, a=6.371e6, dl=2.5 * np.pi / 180.0, om=7.292e-5, f0=1.03124453e-4, g=9.81):\n",
    "    \"\"\"\n",
    "    Compute relative and absolute geostrophic vorticity from geopotential height data.\n",
    "    \n",
    "    Parameters:\n",
    "        z (np.ndarray): Geopotential height data with shape (n_i, n_j, n_k, n_n).\n",
    "        a (float): Radius of the Earth in meters (default: 6.37e6).\n",
    "        dl (float): Grid spacing in radians (default: 2.5 * pi / 180.0).\n",
    "        om (float): Earth's angular velocity in rad/s (default: 7.292e-5).\n",
    "        f0 (float): Reference Coriolis parameter in 1/s (default: 1.03124453e-4).\n",
    "        g (float): Gravitational acceleration in m/s^2 (default: 9.81).\n",
    "        \n",
    "    Returns:\n",
    "        zetag (np.ndarray): Geostrophic relative vorticity.\n",
    "        etag (np.ndarray): Geostrophic absolute vorticity.\n",
    "    \"\"\"\n",
    "    \n",
    "    datatype = np.float64\n",
    "    n_i, n_j, n_k, n_n = z.shape\n",
    "    # Initialize output arrays for relative and absolute vorticity\n",
    "    zetag = np.zeros((n_i, n_j, n_k, n_n), dtype=datatype)\n",
    "    etag = np.zeros((n_i, n_j, n_k, n_n), dtype=datatype)\n",
    "    \n",
    "    # Create a latitude array for the j interior indices.\n",
    "    lat_interior = np.arange(1, n_j - 1) * dl  # shape (n_j-2,)\n",
    "    cos_lat = np.cos(lat_interior).reshape(1, n_j-2, 1, 1)  # shape (1, n_j-2, 1, 1)\n",
    "    tan_lat = np.tan(lat_interior).reshape(1, n_j-2, 1, 1)\n",
    "    sin_lat = np.sin(lat_interior).reshape(1, n_j-2, 1, 1)\n",
    "    \n",
    "    # Compute central differences for the interior points:\n",
    "    # For i-direction (x-direction):\n",
    "    term_i = (z[2:n_i, 1:n_j-1, :, :] - 2 * z[1:n_i-1, 1:n_j-1, :, :] + z[0:n_i-2, 1:n_j-1, :, :]) \\\n",
    "             / ((a * dl * cos_lat) ** 2)\n",
    "    \n",
    "    # For j-direction (y-direction):\n",
    "    term_j = (z[1:n_i-1, 2:n_j, :, :] - 2 * z[1:n_i-1, 1:n_j-1, :, :] + z[1:n_i-1, 0:n_j-2, :, :]) \\\n",
    "             / ((a * dl) ** 2)\n",
    "    \n",
    "    # For the tan(latitude) term (first derivative in j):\n",
    "    term_tan = tan_lat * (z[1:n_i-1, 2:n_j, :, :] - z[1:n_i-1, 0:n_j-2, :, :]) \\\n",
    "               / (2 * dl * a ** 2)\n",
    "    \n",
    "    # Compute geostrophic relative vorticity (zetag) for the interior points:\n",
    "    zetag[1:n_i-1, 1:n_j-1, :, :] = (g / f0) * (term_i + term_j - term_tan)\n",
    "    \n",
    "    # Compute geostrophic absolute vorticity (etag) for the interior points:\n",
    "    etag[1:n_i-1, 1:n_j-1, :, :] = zetag[1:n_i-1, 1:n_j-1, :, :] + 2 * om * sin_lat\n",
    "    \n",
    "    return zetag, etag\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: Read geopotential height data from a file\n",
    "    z = np.fromfile(\"z.dat\", dtype=np.float64).reshape((73, 37, 10, 20), order=\"F\")\n",
    "    \n",
    "    # Dimensions of the input data\n",
    "    n_i, n_j, n_k, n_n = z.shape\n",
    "    \n",
    "    # Compute vorticities\n",
    "    zetag, etag = compute_vorticity(z)\n",
    "    \n",
    "    # Write the outputs to files in Fortran order\n",
    "    zetag.flatten(order=\"F\").tofile(\"zeta_g.dat\")\n",
    "    etag.flatten(order=\"F\").tofile(\"eta_g.dat\")\n",
    "\n",
    "\n",
    "# for test, NOTE slight difference comes from a (6.731 <- 6.73)\n",
    "zetag_test = np.fromfile(\"/mnt/e/proj_yagi/zeta_g.dat\", dtype=np.float32).reshape((n_i, n_j, n_k, n_n),order=\"F\")\n",
    "etag_test = np.fromfile(\"/mnt/e/proj_yagi/eta_g.dat\", dtype=np.float32).reshape((n_i, n_j, n_k, n_n),order=\"F\")\n",
    "display(zetag[41, 17, :, 3],zetag_test[41, 17, :, 3])\n",
    "display(etag[41, 17, :, 3],etag_test[41, 17, :, 3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forcing: vort_g_adv.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculation uses central finite differences to approximate the horizontal gradients of the geopotential\n",
    "height field and the geostrophic absolute vorticity. The resulting advection field is computed as:\n",
    "\n",
    "$$\n",
    "\\text{adv}(i,j,k,n) = \\frac{g}{f_0\\cos(\\phi) (2\\,dl\\,a)^2} \\left[\n",
    "\\bigl(z(i,j+1,k,n)-z(i,j-1,k,n)\\bigr)\\bigl(\\eta_g(i+1,j,k,n)-\\eta_g(i-1,j,k,n)\\bigr) - \\bigl(z(i+1,j,k,n)-z(i-1,j,k,n)\\bigr)\\bigl(\\eta_g(i,j+1,k,n)-\\eta_g(i,j-1,k,n)\\bigr)\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $z$ is the geopotential height.\n",
    "- $\\eta_g$ is the geostrophic absolute vorticity.\n",
    "- $g$ is gravitational acceleration (9.81 m/s²).\n",
    "- $f_0$ is the reference Coriolis parameter (1.03124453×10⁻⁴ s⁻¹).\n",
    "- $a$ is the Earth's radius (6.37×10⁶ m).\n",
    "- $dl$ is the grid spacing in radians, computed as $2.5\\pi/180$.\n",
    "- $\\phi$ is the latitude, computed for interior grid points as $\\phi = (j-1)\\,dl$.\n",
    "\n",
    "**Input Files**\n",
    "\n",
    "- **z.dat**  \n",
    "  An unformatted binary file containing the geopotential height field $z$ with dimensions:\n",
    "  $$\n",
    "  73 \\times 37 \\times 10 \\times 20\n",
    "  $$\n",
    "  (Data is stored in Fortran column-major order.)\n",
    "\n",
    "- **eta_g.dat**  \n",
    "  An unformatted binary file containing the geostrophic absolute vorticity field $\\eta_g$ with dimensions:\n",
    "  $$\n",
    "  73 \\times 37 \\times 10 \\times 20\n",
    "  $$\n",
    "  (Data is stored in Fortran column-major order.)\n",
    "\n",
    "**Output File**\n",
    "\n",
    "- **vort_g_adv.dat**  \n",
    "  An unformatted binary file containing the computed geostrophic vorticity advection field $\\text{adv}$ with dimensions:\n",
    "  $$\n",
    "  73 \\times 37 \\times 10 \\times 20\n",
    "  $$\n",
    "  (Data is written in Fortran column-major order.)\n",
    "\n",
    "**Note**\n",
    "\n",
    "- **Data Ordering:**  \n",
    "   All files are stored in Fortran (column-major) order. In Python, arrays must be reshaped and flattened with `order=\"F\"` to preserve this order.\n",
    "\n",
    "- **Grid Boundaries:**  \n",
    "   The finite difference approximations are applied only to the interior points where neighboring values exist (i.e., $i=2,\\dots,72$ and $j=2,\\dots,36$).\n",
    "\n",
    "- **Broadcasting:**  \n",
    "   The latitude-dependent factor $\\cos(\\phi)$ is computed for each interior $j$ index and broadcasted along the other dimensions.\n",
    "\n",
    "**Usage**\n",
    "\n",
    "1. **Prepare Input:**  \n",
    "   Place `z.dat` and `eta_g.dat` in the working directory. Ensure they are in Fortran order with dimensions 73×37×10×20.\n",
    "\n",
    "2. **Run the Script:**  \n",
    "   Execute the Python script to compute the advection field.\n",
    "\n",
    "3. **Output:**  \n",
    "   The resulting field is saved as `vort_g_adv.dat` (in Fortran order). Diagnostic output is printed for the grid point corresponding to (42,18,k,4) in Fortran indexing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# vort_g_adv.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def compute_vorticity_advection(z, etag, a=6.371e6, dl=2.5 * np.pi / 180.0, f0=1.03124453e-4, g=9.81):\n",
    "    \"\"\"\n",
    "    Compute the geostrophic vorticity advection term for the input geopotential height and vorticity field.\n",
    "    \n",
    "    Parameters:\n",
    "        z (np.ndarray): Geopotential height data with shape (n_i, n_j, n_k, n_n).\n",
    "        etag (np.ndarray): Geostrophic absolute vorticity with shape (n_i, n_j, n_k, n_n).\n",
    "        n_i, n_j, n_k, n_n (int): Dimensions of the input arrays `z` and `etag`.\n",
    "        a (float): Radius of the Earth in meters (default: 6.37e6).\n",
    "        dl (float): Grid spacing in radians (default: 2.5 * pi / 180.0).\n",
    "        f0 (float): Reference Coriolis parameter (default: 1.03124453e-4).\n",
    "        g (float): Gravitational acceleration (default: 9.81).\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: The computed advection term with shape (n_i, n_j, n_k, n_n).\n",
    "    \"\"\"\n",
    "    n_i, n_j, n_k, n_n = z.shape\n",
    "    datatype = np.float64\n",
    "    \n",
    "    # Initialize the output advection array\n",
    "    adv = np.zeros((n_i, n_j, n_k, n_n), dtype=datatype)\n",
    "    \n",
    "    # Define interior slices for i and j indices\n",
    "    I = slice(1, n_i-1)\n",
    "    J = slice(1, n_j-1)\n",
    "\n",
    "    # Latitude array for the j interior indices\n",
    "    lat_array = np.arange(1, n_j-1) * dl  # shape: (n_j-2,)\n",
    "    lat_b = lat_array.reshape(1, n_j-2, 1, 1)  # reshape for broadcasting\n",
    "    \n",
    "    # Compute the scaling factor (common to all interior points)\n",
    "    factor = g / (f0 * np.cos(lat_b)) / ((2 * dl * a) ** 2)  # shape: (1, n_j-2, 1, 1)\n",
    "    \n",
    "    # Compute central finite differences for the horizontal derivatives\n",
    "    # Differences in the j-direction (latitude):\n",
    "    z_jp = z[I, 2:n_j, :, :]   # z(i, j+1, :, :) \n",
    "    z_jm = z[I, 0:n_j-2, :, :]   # z(i, j-1, :, :) \n",
    "\n",
    "    # Differences in the i-direction (longitude):\n",
    "    z_ip = z[2:n_i, J, :, :]   # z(i+1, j, :, :) \n",
    "    z_im = z[0:n_i-2, J, :, :]   # z(i-1, j, :, :)\n",
    "\n",
    "    # Similarly for etag:\n",
    "    etag_jp = etag[I, 2:n_j, :, :]\n",
    "    etag_jm = etag[I, 0:n_j-2, :, :]\n",
    "    etag_ip = etag[2:n_i, J, :, :]\n",
    "    etag_im = etag[0:n_i-2, J, :, :]\n",
    "\n",
    "    # Compute the two terms of the advection expression:\n",
    "    # Term 1: (z(i,j+1)-z(i,j-1))*(etag(i+1,j)-etag(i-1,j))\n",
    "    term1 = (z_jp - z_jm) * (etag_ip - etag_im)\n",
    "    # Term 2: (z(i+1,j)-z(i-1,j))*(etag(i,j+1)-etag(i,j-1))\n",
    "    term2 = (z_ip - z_im) * (etag_jp - etag_jm)\n",
    "\n",
    "    # Compute the advection term for the interior points\n",
    "    adv_interior = factor * (term1 - term2)  # shape (n_i-2, n_j-2, n_k, n_n)\n",
    "\n",
    "    # Insert computed values into the adv array\n",
    "    adv[I, J, :, :] = adv_interior\n",
    "    \n",
    "    return adv\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: Read geopotential height and vorticity data from files\n",
    "    z = np.fromfile(\"z.dat\", dtype=np.float64).reshape((73, 37, 10, 20), order=\"F\")\n",
    "    etag = np.fromfile(\"eta_g.dat\", dtype=np.float64).reshape((73, 37, 10, 20), order=\"F\")\n",
    "    \n",
    "    # Dimensions of the input data\n",
    "    n_i, n_j, n_k, n_n = z.shape\n",
    "    \n",
    "    # Compute the advection term\n",
    "    adv = compute_vorticity_advection(z, etag)\n",
    "    \n",
    "    # Write the output advection field to \"vort_g_adv.dat\" in Fortran order\n",
    "    adv.flatten(order=\"F\").tofile(\"vort_g_adv.dat\")\n",
    "\n",
    "\n",
    "# for test\n",
    "adv_test = z = np.fromfile(\"/mnt/e/proj_yagi/vort_g_adv.dat\", dtype=np.float32).reshape((n_i, n_j, n_k, n_n), order=\"F\")\n",
    "display(adv[41, 17, :, 3],adv_test[41, 17, :, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result: omega_v.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# omega_vort_g_adv.py\n",
    "\n",
    "def compute_vorticity_forcing(adv, sm, p=p_default, dl=dl_default, iw=1, ie=72, js=1, jn=36):\n",
    "    \"\"\"\n",
    "    Compute the Forcing Term F over the interior region using the given vorticity advection and sigma mean arrays.\n",
    "    \n",
    "    Parameters:\n",
    "        adv (np.ndarray): The vorticity advection array, should have shape (n_i, n_j, n_k, n_n)\n",
    "        sm (np.ndarray): The sigma mean array, should have shape (n_k, n_n)\n",
    "        p (np.ndarray): The array of pressure levels (default: standard pressure levels)\n",
    "        dl (float): Latitude differential (default: 2.5*pi/180.0)\n",
    "        iw, ie, js, jn (int): The boundary indices for the interior region (default: 1, 72, 1, 36)\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: The computed forcing term F with shape (n_i, n_j, n_k, n_n)\n",
    "    \"\"\"\n",
    "    # Define constants\n",
    "    pi = np.pi\n",
    "    a = 6.371e6\n",
    "    f0 = 1.03124453e-4\n",
    "    g = 9.81\n",
    "    r = 287.052874\n",
    "    n_i, n_j, n_k, n_n = adv.shape\n",
    "    \n",
    "    # Extract slices from \"adv\"\n",
    "    I = slice(iw, ie)  # i indices\n",
    "    J = slice(js, jn)  # j indices\n",
    "    K = slice(1, n_k-1)  # k indices\n",
    "    N = slice(0, n_n)  # n indices\n",
    "    \n",
    "    adv_center = adv[I, J, K, N]\n",
    "    adv_kp = adv[I, J, 2:n_k, N]  # k+1\n",
    "    adv_km = adv[I, J, 0:n_k-2, N]  # k-1\n",
    "\n",
    "\n",
    "    # For each interior vertical level, compute dp1 and dp2:\n",
    "    dp1_vec = p[0:n_k-2] - p[K]  # shape (8,)\n",
    "    dp2_vec = p[K] - p[2:n_k]  # shape (8,)\n",
    "    dp1_b = dp1_vec.reshape(1, 1, n_k-2, 1)  # broadcast to shape (1,1,8,1)\n",
    "    dp2_b = dp2_vec.reshape(1, 1, n_k-2, 1)\n",
    "\n",
    "    # Get s values for interior k and time steps\n",
    "    s_interior = sm[K, N]  # shape (8, 19)\n",
    "    s_b = s_interior.reshape(1, 1, n_k-2, n_n)  # shape (1,1,8,19)\n",
    "\n",
    "    fac = -1000*(f0/s_b) # shape (1,1,8,19)\n",
    "    # Compute F in the interior region:\n",
    "    diff_term = (dp2_b*adv_km+(dp1_b-dp2_b)*adv_center-dp1_b*adv_kp) / (2*dp1_b*dp2_b)\n",
    "\n",
    "    F_interior = fac * diff_term  # shape (71,35,8,19)\n",
    "\n",
    "    # Allocate full F array and insert computed interior values\n",
    "    F = np.zeros((n_i, n_j, n_k, n_n), dtype=np.float64)\n",
    "    F[I, J, K, N] = F_interior\n",
    "\n",
    "    return F\n",
    "\n",
    "def relax_omega_field(F, w, sm, tolerance=0.001 , max_iter=20000 , p=p_default, dl=dl_default, iw=1, ie=72, js=1, jn=36):\n",
    "    \"\"\"\n",
    "    Perform relaxation iteration for the omega field using the given forcing term and initial omega field.\n",
    "    \n",
    "    Parameters:\n",
    "        F (np.ndarray): The forcing term array, should have shape (n_i, n_j, n_k, n_n)\n",
    "        w (np.ndarray): The initial omega field array, should have shape (n_i, n_j, n_k, n_n)\n",
    "        sm (np.ndarray): The sigma mean array, should have shape (n_k, n_n)\n",
    "        p (np.ndarray): The array of pressure levels (default: standard pressure levels)\n",
    "        dl (float): Latitude differential (default: 2.5*pi/180.0)\n",
    "        iw, ie, js, jn (int): The boundary indices for the interior region (default: 1, 72, 1, 36)\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: The updated omega field w after relaxation iterations\n",
    "    \"\"\"\n",
    "    # Define constants\n",
    "    pi = np.pi\n",
    "    a = 6.371e6\n",
    "    f0 = 1.03124453e-4\n",
    "    g = 9.81\n",
    "    r = 287.052874\n",
    "    n_i, n_j, n_k, n_n = w.shape  # Recompute dimensions for omega field\n",
    "\n",
    "    for m in range(max_iter):\n",
    "        # Extract interior region of w for current iteration:\n",
    "        I = slice(iw, ie)  # i indices\n",
    "        J = slice(js, jn)  # j indices\n",
    "        K = slice(1, n_k-1)  # k indices\n",
    "        N = slice(0, n_n)  # n indices\n",
    "\n",
    "        w_center = w[I, J, K, N]  # shape: (71, 35, 8, 19)\n",
    "        w_ip = w[2:n_i, J, K, N]\n",
    "        w_im = w[0:n_i-2, J, K, N]\n",
    "        w_jp = w[I, 2:n_j, K, N]\n",
    "        w_jm = w[I, 0:n_j-2, K, N]\n",
    "\n",
    "        # Horizontal second derivatives\n",
    "        d2w_di2 = (w_ip - 2 * w_center + w_im) / ((a * dl * np.cos(np.arange(js, jn) * dl).reshape(1, jn-js, 1, 1)) ** 2)\n",
    "        d2w_dj2 = (w_jp - 2 * w_center + w_jm) / ((a * dl) ** 2)\n",
    "        dw_dj = (w_jp - w_jm) / (2 * dl * a**2)\n",
    "\n",
    "        # Vertical neighbors for interior: \n",
    "        w_km = w[I, J, 0:n_k-2, N]  # shape: (71, 35, 7, 19)\n",
    "        w_kp = w[I, J, 2:n_k, N]  # shape: (71, 35, 7, 19)\n",
    "\n",
    "        # Compute vertical coupling term (fully vectorized)\n",
    "        dp1_b_relax = (p[0:(n_k-2)] - p[K]).reshape(1, 1, n_k-2, 1)  # shape (1,1,8,1)\n",
    "        dp2_b_relax = (p[K] - p[2:n_k]).reshape(1, 1, n_k-2, 1)  # shape (1,1,8,1)\n",
    "        s_b = sm[K, N].reshape(1, 1, n_k-2, n_n)  # shape (1,1,8,19)\n",
    "\n",
    "        d2w_dp2 = ((dp2_b_relax / (2 * dp1_b_relax) + 0.5) * w_km -\n",
    "                   (dp2_b_relax / (2 * dp1_b_relax) + dp1_b_relax / (2 * dp2_b_relax) + 1.0) * w_center +\n",
    "                   (dp1_b_relax / (2 * dp2_b_relax) + 0.5) * w_kp) / (dp1_b_relax * dp2_b_relax)\n",
    "\n",
    "        # Extract F for the interior region from F (using same slices as in relaxation)\n",
    "        F_interior = F[I, J, K, N]\n",
    "\n",
    "        # Compute relaxation update Ri (vectorized over i, j, k, n)\n",
    "        Ri = (d2w_di2 - np.tan(np.arange(js, jn) * dl).reshape(1, jn-js, 1, 1) * dw_dj +\n",
    "              d2w_dj2 + (f0**2 / s_b) * d2w_dp2 - F_interior)\n",
    "\n",
    "        # Compute denominator\n",
    "        denom = (2 / ((a * dl * np.cos(np.arange(js, jn) * dl).reshape(1, jn-js, 1, 1)) ** 2) +\n",
    "                 2 / ((a * dl) ** 2) +\n",
    "                 (f0**2 / s_b) * (dp2_b_relax / (2 * dp1_b_relax) + dp1_b_relax / (2 * dp2_b_relax) + 1.0) / (dp1_b_relax * dp2_b_relax))\n",
    "\n",
    "        c_update = Ri / denom\n",
    "        w[I, J, K, N] += c_update\n",
    "\n",
    "        absmax = np.max(np.abs(c_update))\n",
    "        if absmax < tolerance:\n",
    "            break\n",
    "\n",
    "    return w\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Assume you have preloaded `vort_g_adv` and `sm` arrays from files\n",
    "    adv = np.fromfile(\"vort_g_adv.dat\", dtype=np.float64).reshape((73, 37, 10, 20), order=\"F\")\n",
    "    sm = np.fromfile(\"sigma_mean.dat\", dtype=np.float64).reshape((10, 20), order=\"F\")\n",
    "    \n",
    "    # Compute Forcing Term F\n",
    "    F = compute_vorticity_forcing(adv, sm)\n",
    "    \n",
    "    # Initialize omega field w (could be zeros or some initial guess)\n",
    "    w_initial = np.zeros_like(res)\n",
    "    \n",
    "    # Relax omega field\n",
    "    w_relaxed = relax_omega_field(F, w_initial, sm)\n",
    "    \n",
    "    # Optionally, write the output to file\n",
    "    w_relaxed.flatten(order=\"F\").tofile(\"omega_vort_g_adv.dat\")\n",
    "w_test = np.fromfile(\"/mnt/e/proj_yagi/omega_vort_g_adv.dat\", dtype=np.float32).reshape((73,37,9,20), order=\"F\")\n",
    "display(w_relaxed[30,10,:,10],w_test[30,10,:,10])\n",
    "display(np.max(np.abs(w_relaxed[:,:,:-1,1:-1]-w_test[:,:,:,1:-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature advecton omega: omega_T.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# omega_T.py\n",
    "\n",
    "# import cupy as np\n",
    "import numpy as np\n",
    "\n",
    "# Define constants\n",
    "pi = np.pi\n",
    "a = 6.371e6\n",
    "f0 = 1.03124453e-4\n",
    "g = 9.81\n",
    "r = 287.052874\n",
    "\n",
    "# Pressure levels (hPa)\n",
    "p_default = np.array([1000., 925., 850., 700., 600., 500., 400., 300., 200., 100.], dtype=np.float64)\n",
    "dl_default = 2.5 * pi / 180.0  # Default latitude differential\n",
    "\n",
    "def compute_temp_adv_forcing(adv, sm, p=p_default, dl=dl_default, iw=1, ie=72, js=1, jn=36):\n",
    "    \"\"\"\n",
    "    Compute the Forcing Term F over the interior region using the given residue and sigma mean arrays.\n",
    "    \n",
    "    Parameters:\n",
    "        res (np.ndarray): The residue array, should have shape (n_i, n_j, n_k, n_n)\n",
    "        sm (np.ndarray): The sigma mean array, should have shape (n_k, n_n)\n",
    "        p (np.ndarray): The array of pressure levels (default: standard pressure levels)\n",
    "        dl (float): Latitude differential (default: 2.5*pi/180.0)\n",
    "        iw, ie, js, jn (int): The boundary indices for the interior region (default: 1, 72, 1, 36)\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: The computed forcing term F with shape (n_i, n_j, n_k, n_n)\n",
    "    \"\"\"\n",
    "    # Define constants\n",
    "    pi = np.pi\n",
    "    a = 6.371e6\n",
    "    f0 = 1.03124453e-4\n",
    "    g = 9.81\n",
    "    r = 287.052874\n",
    "    n_i, n_j, n_k, n_n = adv.shape\n",
    "    \n",
    "    # Extract slices from \"res\"\n",
    "    I = slice(iw, ie)  # i indices\n",
    "    J = slice(js, jn)  # j indices\n",
    "    K = slice(1, n_k-1)  # k indices\n",
    "    N = slice(0, n_n)  # n indices\n",
    "    \n",
    "    adv_center = adv[I, J, K, N]\n",
    "    adv_ip = adv[2:ie+1, J, K, N]  # i+1\n",
    "    adv_im = adv[0:ie-1, J, K, N]  # i-1\n",
    "    adv_jp = adv[I, 2:jn+1, K, N]  # j+1\n",
    "    adv_jm = adv[I, 0:jn-1, K, N]  # j-1\n",
    "\n",
    "    # Compute latitude for interior j indices\n",
    "    j_indices = np.arange(js, jn)   # shape (34,)\n",
    "    lat = j_indices * dl  # shape (34,)\n",
    "    cos_lat = np.cos(lat).reshape(1, jn-js, 1, 1)\n",
    "    tan_lat = np.tan(lat).reshape(1, jn-js, 1, 1)\n",
    "\n",
    "    # Finite differences for horizontal derivatives:\n",
    "    term1 = (adv_ip - 2 * adv_center + adv_im) / ((a * dl * cos_lat) ** 2)\n",
    "    term2 = (adv_jp - 2 * adv_center + adv_jm) / ((a * dl) ** 2)\n",
    "    term3 = (tan_lat / (2 * dl * a ** 2)) * (adv_jp - adv_jm)\n",
    "\n",
    "    # For each interior vertical level, compute dp1 and dp2:\n",
    "    dp1_vec = p[0:n_k-2] - p[K]  # shape (8,)\n",
    "    dp2_vec = p[K] - p[2:n_k]  # shape (8,)\n",
    "    dp1_b = dp1_vec.reshape(1, 1, n_k-2, 1)  # broadcast to shape (1,1,8,1)\n",
    "    dp2_b = dp2_vec.reshape(1, 1, n_k-2, 1)\n",
    "\n",
    "    # Get s values for interior k and time steps\n",
    "    s_interior = sm[K, N]  # shape (8, 19)\n",
    "    s_b = s_interior.reshape(1, 1, n_k-2, n_n)  # shape (1,1,8,19)\n",
    "\n",
    "    # Compute fac (forcing factor); note the empirical factor 1000 for unit conversion.\n",
    "    p_interior = p[K].reshape(n_k-2, 1)  # shape (8,1)\n",
    "    fac = -(1000) * (r / (p_interior * s_interior))  # shape (8,19)\n",
    "    fac = fac.reshape(1, 1, n_k-2, n_n)  # reshape to (1,1,8,19)\n",
    "\n",
    "    # Compute F in the interior region:\n",
    "    F_interior = fac * (term1 + term2 - term3)  # shape (71,35,8,19)\n",
    "\n",
    "    # Allocate full F array and insert computed interior values\n",
    "    F = np.zeros((n_i, n_j, n_k, n_n), dtype=np.float64)\n",
    "    F[I, J, K, N] = F_interior\n",
    "\n",
    "    return F\n",
    "\n",
    "def relax_omega_field(F, w, sm, tolerance=0.001 , max_iter=20000 , p=p_default, dl=dl_default, iw=1, ie=72, js=1, jn=36):\n",
    "    \"\"\"\n",
    "    Perform relaxation iteration for the omega field using the given forcing term and initial omega field.\n",
    "    \n",
    "    Parameters:\n",
    "        F (np.ndarray): The forcing term array, should have shape (n_i, n_j, n_k, n_n)\n",
    "        w (np.ndarray): The initial omega field array, should have shape (n_i, n_j, n_k, n_n)\n",
    "        sm (np.ndarray): The sigma mean array, should have shape (n_k, n_n)\n",
    "        p (np.ndarray): The array of pressure levels (default: standard pressure levels)\n",
    "        dl (float): Latitude differential (default: 2.5*pi/180.0)\n",
    "        iw, ie, js, jn (int): The boundary indices for the interior region (default: 1, 72, 1, 36)\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: The updated omega field w after relaxation iterations\n",
    "    \"\"\"\n",
    "    # Define constants\n",
    "    pi = np.pi\n",
    "    a = 6.371e6\n",
    "    f0 = 1.03124453e-4\n",
    "    g = 9.81\n",
    "    r = 287.052874\n",
    "    n_i, n_j, n_k, n_n = w.shape  # Recompute dimensions for omega field\n",
    "\n",
    "    for m in range(max_iter):\n",
    "        # Extract interior region of w for current iteration:\n",
    "        I = slice(iw, ie)  # i indices\n",
    "        J = slice(js, jn)  # j indices\n",
    "        K = slice(1, n_k-1)  # k indices\n",
    "        N = slice(0, n_n)  # n indices\n",
    "\n",
    "        w_center = w[I, J, K, N]  # shape: (71, 35, 8, 19)\n",
    "        w_ip = w[2:n_i, J, K, N]\n",
    "        w_im = w[0:n_i-2, J, K, N]\n",
    "        w_jp = w[I, 2:n_j, K, N]\n",
    "        w_jm = w[I, 0:n_j-2, K, N]\n",
    "\n",
    "        # Horizontal second derivatives\n",
    "        d2w_di2 = (w_ip - 2 * w_center + w_im) / ((a * dl * np.cos(np.arange(js, jn) * dl).reshape(1, jn-js, 1, 1)) ** 2)\n",
    "        d2w_dj2 = (w_jp - 2 * w_center + w_jm) / ((a * dl) ** 2)\n",
    "        dw_dj = (w_jp - w_jm) / (2 * dl * a**2)\n",
    "\n",
    "        # Vertical neighbors for interior: \n",
    "        w_km = w[I, J, 0:n_k-2, N]  # shape: (71, 35, 7, 19)\n",
    "        w_kp = w[I, J, 2:n_k, N]  # shape: (71, 35, 7, 19)\n",
    "\n",
    "        # Compute vertical coupling term (fully vectorized)\n",
    "        dp1_b_relax = (p[0:(n_k-2)] - p[K]).reshape(1, 1, n_k-2, 1)  # shape (1,1,8,1)\n",
    "        dp2_b_relax = (p[K] - p[2:n_k]).reshape(1, 1, n_k-2, 1)  # shape (1,1,8,1)\n",
    "        s_b = sm[K, N].reshape(1, 1, n_k-2, n_n)  # shape (1,1,8,19)\n",
    "\n",
    "        d2w_dp2 = ((dp2_b_relax / (2 * dp1_b_relax) + 0.5) * w_km -\n",
    "                   (dp2_b_relax / (2 * dp1_b_relax) + dp1_b_relax / (2 * dp2_b_relax) + 1.0) * w_center +\n",
    "                   (dp1_b_relax / (2 * dp2_b_relax) + 0.5) * w_kp) / (dp1_b_relax * dp2_b_relax)\n",
    "\n",
    "        # Extract F for the interior region from F (using same slices as in relaxation)\n",
    "        F_interior = F[I, J, K, N]\n",
    "\n",
    "        # Compute relaxation update Ri (vectorized over i, j, k, n)\n",
    "        Ri = (d2w_di2 - np.tan(np.arange(js, jn) * dl).reshape(1, jn-js, 1, 1) * dw_dj +\n",
    "              d2w_dj2 + (f0**2 / s_b) * d2w_dp2 - F_interior)\n",
    "\n",
    "        # Compute denominator\n",
    "        denom = (2 / ((a * dl * np.cos(np.arange(js, jn) * dl).reshape(1, jn-js, 1, 1)) ** 2) +\n",
    "                 2 / ((a * dl) ** 2) +\n",
    "                 (f0**2 / s_b) * (dp2_b_relax / (2 * dp1_b_relax) + dp1_b_relax / (2 * dp2_b_relax) + 1.0) / (dp1_b_relax * dp2_b_relax))\n",
    "\n",
    "        c_update = Ri / denom\n",
    "        w[I, J, K, N] += c_update\n",
    "\n",
    "        absmax = np.max(np.abs(c_update))\n",
    "        if absmax < tolerance:\n",
    "            break\n",
    "\n",
    "    return w\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Assume you have preloaded `res` and `sm` arrays from files\n",
    "    adv = np.fromfile(\"T_g_adv.dat\", dtype=np.float64).reshape((73, 37, 10, 20), order=\"F\")\n",
    "    sm = np.fromfile(\"sigma_mean.dat\", dtype=np.float64).reshape((10, 20), order=\"F\")\n",
    "    \n",
    "    # Compute Forcing Term F\n",
    "    F = compute_temp_adv_forcing(adv, sm)\n",
    "    \n",
    "    # Initialize omega field w (could be zeros or some initial guess)\n",
    "    w_initial = np.zeros_like(adv)\n",
    "    \n",
    "    # Relax omega field\n",
    "    # w_relaxed = relax_omega_field(F, w_initial, sm, max_iter=200000, tolerance=0.00001) # for cupy\n",
    "    w_relaxed = relax_omega_field(F, w_initial, sm)\n",
    "    \n",
    "    # Optionally, write the output to file\n",
    "    w_relaxed.flatten(order=\"F\").tofile(\"omega_T_g_adv.dat\")\n",
    "w_test = np.fromfile(\"/mnt/e/proj_yagi/omega_T_g_adv.dat\", dtype=np.float32).reshape((73,37,9,20), order=\"F\")\n",
    "display(w_relaxed[4,5,:,6],w_test[4,5,:,6])\n",
    "display(np.max(np.abs(w_relaxed[:,:,:-1,1:-1]-w_test[:,:,:,1:-1])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
